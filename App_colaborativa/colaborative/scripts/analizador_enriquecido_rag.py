# =============================================================================
# --- EXTENSIÃ“N: AnÃ¡lisis de compilaciones con guardado y reporte ---
# =============================================================================
import sqlite3
import json
from datetime import datetime
from pathlib import Path

def analizar_compilacion_y_guardar(path_archivo: str, analizador, db_path: str = None, exportar_json: bool = True) -> dict:
    """
    Analiza una compilaciÃ³n de sentencias, guarda los resultados en la base de datos
    y genera un informe resumido para verificaciÃ³n.
    """
    print(f"\nâš–ï¸ Analizando y registrando compilaciÃ³n: {path_archivo}")

    texto = analizador.extraer_texto_completo(path_archivo)
    if not texto:
        print("[!] No se pudo extraer texto del archivo.")
        return {"status": "error", "detalle": "no se extrajo texto"}

    sentencias = dividir_sentencias(texto)
    if not sentencias:
        print("[!] No se detectaron sentencias en la compilaciÃ³n.")
        return {"status": "error", "detalle": "no se detectaron sentencias"}

    print(f"ğŸ“š {len(sentencias)} sentencias detectadas. Iniciando anÃ¡lisis...")

    # Determinar ruta de base de datos
    if not db_path:
        base_path = Path(__file__).resolve().parents[1]
        db_path = base_path / "bases_rag" / "cognitiva" / "metadatos.db"
    Path(db_path).parent.mkdir(parents=True, exist_ok=True)

    # ConexiÃ³n a la base
    conn = sqlite3.connect(db_path)
    cur = conn.cursor()

    cur.execute("""
        CREATE TABLE IF NOT EXISTS perfiles_cognitivos (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            archivo TEXT,
            titulo_sentencia TEXT,
            autor TEXT,
            perfil_general TEXT,
            fecha_analisis TEXT,
            total_palabras INTEGER,
            palabras_clave TEXT,
            tipo_documento TEXT,
            metadata_json TEXT
        )
    """)

    resumen = {
        "archivo_compilacion": str(path_archivo),
        "fecha": datetime.now().isoformat(),
        "total_sentencias": len(sentencias),
        "registradas": 0,
        "errores": 0,
        "detalles": []
    }

    for i, s in enumerate(sentencias, 1):
        print(f"\nğŸ§¾ [{i}/{len(sentencias)}] Analizando: {s['titulo'][:80]}...")
        try:
            resultado = analizador.analizar_documento_completo(s['texto'], silent=True)
            discern = resultado.get("discernimiento", {})
            perfil = discern.get("perfil_general", "No determinado")
            palabras_clave = ", ".join(list(resultado.get("palabras_clave", {}).keys())[:10])
            total_palabras = resultado.get("estadisticas", {}).get("total_palabras", 0)

            cur.execute("""
                INSERT INTO perfiles_cognitivos
                (archivo, titulo_sentencia, autor, perfil_general, fecha_analisis,
                 total_palabras, palabras_clave, tipo_documento, metadata_json)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                Path(path_archivo).name,
                s['titulo'][:250],
                resultado.get("autor_referencia_principal", {}).get("nombre", "No identificado"),
                perfil,
                datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                total_palabras,
                palabras_clave,
                "sentencia_compilada",
                json.dumps(resultado, ensure_ascii=False)[:5000]
            ))

            resumen["registradas"] += 1
            resumen["detalles"].append({
                "titulo": s["titulo"],
                "perfil": perfil,
                "autor": resultado.get("autor_referencia_principal", {}).get("nombre", "No identificado"),
                "palabras": total_palabras,
                "palabras_clave": palabras_clave.split(",")[:5],
                "analisis": resultado
            })
        except Exception as e:
            resumen["errores"] += 1
            resumen["detalles"].append({
                "titulo": s["titulo"],
                "error": str(e)
            })
            print(f"   [!] Error analizando sentencia: {e}")

    conn.commit()
    conn.close()

    print(f"\nâœ… {resumen['registradas']} sentencias registradas correctamente ({resumen['errores']} con error).")

    # Informe TXT
    informe = (
        "\nğŸ“˜ INFORME DE ANÃLISIS DE COMPILACIÃ“N\n"
        f"Archivo: {Path(path_archivo).name}\n"
        f"Fecha: {resumen['fecha']}\n"
        f"Sentencias analizadas: {resumen['total_sentencias']}\n"
        f"Registradas correctamente: {resumen['registradas']}\n"
        f"Con errores: {resumen['errores']}\n"
        "\n--- Detalle de sentencias ---\n"
    )
    for d in resumen["detalles"]:
        informe += f"â€¢ {d.get('titulo')[:100]} â†’ Perfil: {d.get('perfil', 'N/A')} | Autor: {d.get('autor', '-')}\n"

    informe_path = Path(path_archivo).with_suffix(".informe.txt")
    with open(informe_path, "w", encoding="utf-8") as f:
        f.write(informe)
    print(f"\nğŸ—‚ï¸ Informe generado en: {informe_path}")

    # Informe JSON
    if exportar_json:
        json_path = Path(path_archivo).with_suffix(".informe.json")
        with open(json_path, "w", encoding="utf-8") as jf:
            json.dump(resumen, jf, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ Informe JSON generado: {json_path}")

    return resumen

# =============================================================================
# --- EXTENSIÃ“N: VerificaciÃ³n inteligente del informe por IA (segura) ---
# =============================================================================
import difflib

def verificar_informe_con_ia(reporte: dict, analizador, reanalizar_si_falla: bool = True) -> dict:
    """
    Verifica la coherencia y utilidad de los datos guardados.
    No inventa datos; solo marca, corrige o reanaliza fragmentos invÃ¡lidos.
    """
    print("\nğŸ¤– Iniciando verificaciÃ³n inteligente del informe...")
    if not reporte or "detalles" not in reporte:
        print("[!] No hay informe vÃ¡lido para verificar.")
        return {"estado": "error", "detalle": "informe invÃ¡lido o vacÃ­o"}

    verificacion = {
        "total": len(reporte["detalles"]),
        "validos": 0,
        "invalidos": 0,
        "reanalizados": 0,
        "detalles": []
    }

    for item in reporte["detalles"]:
        titulo = item.get("titulo", "Sin tÃ­tulo")
        perfil = item.get("perfil")
        palabras = item.get("palabras", 0)
        autor = item.get("autor", "No identificado")
        errores_previos = item.get("error")

        invalido = False
        razon = None

        if errores_previos:
            invalido = True
            razon = f"Error previo en anÃ¡lisis: {errores_previos}"
        elif palabras < 100:
            invalido = True
            razon = f"Texto demasiado breve ({palabras} palabras)"
        elif not perfil or perfil.strip() == "No determinado":
            invalido = True
            razon = "No se detectÃ³ perfil de discernimiento"
        elif titulo and any(
            difflib.SequenceMatcher(None, titulo.lower(), o["titulo"].lower()).ratio() > 0.9
            for o in verificacion["detalles"] if "titulo" in o
        ):
            invalido = True
            razon = "TÃ­tulo duplicado o redundante"

        if invalido:
            verificacion["invalidos"] += 1
            registro = {"titulo": titulo, "razon": razon, "accion": "Pendiente"}
            print(f"âš ï¸ Dato invÃ¡lido: {titulo[:80]} â†’ {razon}")

            if reanalizar_si_falla:
                try:
                    print(f"   ğŸ”„ Reanalizando sentencia: {titulo[:80]}...")
                    texto_reanalizado = item.get("analisis", {}).get("texto_completo", "")
                    if texto_reanalizado:
                        nuevo_resultado = analizador.analizar_documento_completo(texto_reanalizado, silent=True)
                        if nuevo_resultado and "discernimiento" in nuevo_resultado:
                            nuevo_perfil = nuevo_resultado["discernimiento"].get("perfil_general", "No determinado")
                            if nuevo_perfil != "No determinado":
                                registro["accion"] = f"Corregido (nuevo perfil: {nuevo_perfil})"
                                verificacion["reanalizados"] += 1
                            else:
                                registro["accion"] = "Reanalizado sin cambios"
                        else:
                            registro["accion"] = "ReanÃ¡lisis sin resultado Ãºtil"
                    else:
                        registro["accion"] = "Texto no localizado"
                except Exception as e:
                    registro["accion"] = f"Error en reanÃ¡lisis: {e}"

            verificacion["detalles"].append(registro)
        else:
            verificacion["validos"] += 1
            verificacion["detalles"].append({
                "titulo": titulo,
                "estado": "vÃ¡lido",
                "perfil": perfil,
                "autor": autor
            })

    resumen = (
        f"\nğŸ“Š VERIFICACIÃ“N FINAL\n"
        f"Total revisados: {verificacion['total']}\n"
        f"VÃ¡lidos: {verificacion['validos']}\n"
        f"InvÃ¡lidos: {verificacion['invalidos']}\n"
        f"Reanalizados exitosamente: {verificacion['reanalizados']}\n"
    )
    print(resumen)

    informe_path = Path(reporte["archivo_compilacion"]).with_suffix(".verificacion.txt")
    with open(informe_path, "w", encoding="utf-8") as f:
        f.write(resumen)
        for d in verificacion["detalles"]:
            linea = f"â€¢ {d['titulo'][:100]} â†’ {d.get('accion', d.get('estado', ''))}\n"
            f.write(linea)
    print(f"ğŸ—‚ï¸ VerificaciÃ³n registrada en: {informe_path}")

    return verificacion
# =============================================================================
# --- EXTENSIÃ“N: AuditorÃ­a cruzada entre informe y base de datos (RAG-DB) ---
# =============================================================================
def auditar_informe_vs_base(reporte: dict, db_path: str = None) -> dict:
    """
    Audita la coherencia entre el informe de anÃ¡lisis y los registros guardados
    en la base 'metadatos.db'. No modifica datos: solo compara y reporta.
    """
    print("\nğŸ§® Iniciando auditorÃ­a cruzada RAG â†” Base de Datos")
    import sqlite3
    from pathlib import Path

    if not reporte or "detalles" not in reporte:
        print("[!] Informe invÃ¡lido o vacÃ­o.")
        return {"estado": "error", "detalle": "informe invÃ¡lido"}

    if not db_path:
        base_path = Path(__file__).resolve().parents[1]
        db_path = base_path / "bases_rag" / "cognitiva" / "metadatos.db"

    if not Path(db_path).exists():
        print(f"[!] No se encontrÃ³ la base en {db_path}")
        return {"estado": "error", "detalle": "base no encontrada"}

    conn = sqlite3.connect(db_path)
    cur = conn.cursor()
    cur.execute("SELECT titulo_sentencia, perfil_general, autor, archivo FROM perfiles_cognitivos")
    registros_db = cur.fetchall()
    conn.close()

    resumen = {
        "total_informe": len(reporte["detalles"]),
        "total_db": len(registros_db),
        "coincidencias": 0,
        "faltantes_en_db": 0,
        "diferencias": 0,
        "detalles": []
    }

    def buscar_en_db(titulo):
        for (t, perfil, autor, archivo) in registros_db:
            if titulo.lower() in t.lower() or t.lower() in titulo.lower():
                return {"titulo": t, "perfil": perfil, "autor": autor, "archivo": archivo}
        return None

    for d in reporte["detalles"]:
        titulo = d.get("titulo", "Sin tÃ­tulo")
        perfil_rag = d.get("perfil", "No determinado")
        autor_rag = d.get("autor", "No identificado")

        registro_db = buscar_en_db(titulo)

        if registro_db is None:
            resumen["faltantes_en_db"] += 1
            resumen["detalles"].append({
                "titulo": titulo,
                "estado": "âŒ No encontrado en DB"
            })
            print(f"âš ï¸ No se encontrÃ³ en DB: {titulo[:80]}")
            continue

        perfil_db = registro_db["perfil"]
        autor_db = registro_db["autor"]

        if perfil_db == perfil_rag and autor_db == autor_rag:
            resumen["coincidencias"] += 1
        else:
            resumen["diferencias"] += 1
            razon = []
            if perfil_db != perfil_rag:
                razon.append(f"Perfil distinto (DB: {perfil_db} / RAG: {perfil_rag})")
            if autor_db != autor_rag:
                razon.append(f"Autor distinto (DB: {autor_db} / RAG: {autor_rag})")
            resumen["detalles"].append({
                "titulo": titulo,
                "estado": "âš ï¸ Diferencias detectadas",
                "razon": "; ".join(razon)
            })
            print(f"âš ï¸ Diferencias en {titulo[:80]} â†’ {razon}")

    informe_audit = (
        "\nğŸ“‹ AUDITORÃA CRUZADA RAG â†” BASE DE DATOS\n"
        f"Archivo: {Path(reporte['archivo_compilacion']).name}\n"
        f"Registros en informe: {resumen['total_informe']}\n"
        f"Registros en base: {resumen['total_db']}\n"
        f"Coincidencias exactas: {resumen['coincidencias']}\n"
        f"Faltantes en DB: {resumen['faltantes_en_db']}\n"
        f"Diferencias detectadas: {resumen['diferencias']}\n"
        "\n--- Detalle ---\n"
    )
    for d in resumen["detalles"]:
        informe_audit += f"â€¢ {d['titulo'][:100]} â†’ {d['estado']}"
        if "razon" in d:
            informe_audit += f" ({d['razon']})"
        informe_audit += "\n"

    audit_path = Path(reporte["archivo_compilacion"]).with_suffix(".audit.txt")
    with open(audit_path, "w", encoding="utf-8") as f:
        f.write(informe_audit)

    print(f"\nğŸ—‚ï¸ AuditorÃ­a completada â†’ {audit_path}")
    return resumen
# =============================================================================
# --- UTILIDAD: DivisiÃ³n automÃ¡tica de sentencias en compilaciones ---
# =============================================================================
import re

def dividir_sentencias(texto: str) -> list:
    """
    Divide un texto de compilaciÃ³n en sentencias individuales usando:
    - TÃ­tulos/capÃ­tulos/temas (CAPÃTULO, TEMA, CASO, SENTENCIA, Expediente, Causa, Autos)
    - Estructura de sentencia (VISTO, CONSIDERANDO, RESUELVO, FALLO)
    Devuelve una lista de dicts: {'titulo': ..., 'texto': ...}
    """
    # PatrÃ³n para tÃ­tulos/capÃ­tulos/temas/expediente
    patron_titulo = re.compile(
        r'(CAP[IÃ]TULO\s+\d+|TEMA\s*:\s*[^\n]+|CASO\s*:\s*[^\n]+|SENTENCIA\s*\d+|Expediente\s*[^\n]+|Causa\s*[^\n]+|Autos\s*[^\n]+)',
        re.IGNORECASE
    )
    # PatrÃ³n para estructura de sentencia
    patron_sentencia = re.compile(
        r'(VISTO[\s\S]{0,500}?CONSIDERANDO[\s\S]{0,500}?RESUELVO[\s\S]{0,500}?FALLO[\s\S]{0,500}?)',
        re.IGNORECASE
    )

    # Buscar tÃ­tulos y posiciones
    titulos = [(m.start(), m.group()) for m in patron_titulo.finditer(texto)]
    fragmentos = []

    if titulos:
        # Dividir por tÃ­tulos
        for i, (pos, titulo) in enumerate(titulos):
            inicio = pos
            fin = titulos[i+1][0] if i+1 < len(titulos) else len(texto)
            fragmento = texto[inicio:fin]
            fragmentos.append({'titulo': titulo.strip(), 'texto': fragmento.strip()})
    else:
        # Si no hay tÃ­tulos, buscar por estructura de sentencia
        for m in patron_sentencia.finditer(texto):
            fragmentos.append({'titulo': 'Sentencia detectada', 'texto': m.group().strip()})

    return fragmentos
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ” ANALIZADOR ENRIQUECIDO PARA INFORMES GEMINI
===============================================

Extrae informaciÃ³n adicional de los PDFs para informes mÃ¡s completos:
- Autores citados y frecuencia de menciones
- Palabras clave jurÃ­dicas y frecuencias
- Conceptos centrales
- Posiciones doctrinales detectadas
- EstadÃ­sticas textuales avanzadas

FECHA: 11 NOV 2025
"""

import re
import sqlite3
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from collections import Counter
import json
from dataclasses import dataclass

try:
    import fitz  # PyMuPDF
except ImportError:
    print("âš ï¸ PyMuPDF no instalado. Ejecutar: pip install PyMuPDF")
    fitz = None


@dataclass
class PerfilHeuristico:
    """
    Estructura para ajustar pesos del anÃ¡lisis de discernimiento.
    Permite tunear la sensibilidad de cada indicador.
    """
    w_coherencia: float = 0.40
    w_resolutividad: float = 0.30
    w_tension: float = 0.50
    w_tension_pru: float = 0.50
    w_reflexividad_pru: float = 0.40
    w_principialismo_pru: float = 0.20


class AnalizadorEnriquecidoRAG:
    """Analiza documentos PDF para extraer informaciÃ³n enriquecida"""
    
    def __init__(self):
        self.base_path = Path(__file__).parent.parent
        self.pdfs_path = self.base_path / "colaborative/data/pdfs/general"
        
        # Patrones para detectar autores
        self.patron_autores = re.compile(
            r'\b([A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+(?:\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+){1,3})\b',
            re.UNICODE
        )
        
        # Palabras clave jurÃ­dicas comunes
        self.terminos_juridicos = {
            'tutela', 'derecho', 'norma', 'ley', 'cÃ³digo', 'constituciÃ³n',
            'jurisprudencia', 'doctrina', 'tribunal', 'sentencia', 'fallo',
            'proceso', 'procedimiento', 'acciÃ³n', 'recurso', 'demanda',
            'prueba', 'juicio', 'jurisdicciÃ³n', 'competencia', 'legitimaciÃ³n',
            'responsabilidad', 'obligaciÃ³n', 'contrato', 'acuerdo', 'daÃ±o',
            'reparaciÃ³n', 'indemnizaciÃ³n', 'sanciÃ³n', 'pena', 'delito',
            'principio', 'garantÃ­a', 'protecciÃ³n', 'amparo', 'defensa',
            'derechos fundamentales', 'debido proceso', 'seguridad jurÃ­dica'
        }
        
        # Patrones de posicionamiento doctrinal
        self.patrones_posicion = {
            'a favor': re.compile(r'\b(estamos?\s+de\s+acuerdo|sostenemos?\s+que|consideramos?\s+que|propone?mos|defendemos?)\b', re.I),
            'en contra': re.compile(r'\b(rechaza?mos|nos\s+oponemos|criticamos?|cuestionamos?|discrepamos?)\b', re.I),
            'neutral': re.compile(r'\b(se\s+puede\s+sostener|algunos?\s+autores?|la\s+doctrina|existen\s+diferentes)\b', re.I),
            'critico': re.compile(r'\b(sin\s+embargo|no\s+obstante|por\s+el\s+contrario|a\s+pesar\s+de|cabe\s+seÃ±alar)\b', re.I)
        }
        
        # ğŸ” PATRONES DE AUTORIDAD Y Ã‰NFASIS
        self.marcadores_autoridad = {
            'cita_libro': re.compile(r'"([^"]+)"\s*(?:\(|\[)([A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±\s]+),?\s*(\d{4})', re.UNICODE),
            'cita_norma': re.compile(r'\b(ley|cÃ³digo|constituciÃ³n|decreto|resoluciÃ³n|artÃ­culo|art\.?)\s+(?:n[Â°Âº]?\.?\s*)?(\d+)', re.I),
            'doctrina_establecida': re.compile(r'\b(doctrina\s+(?:mayoritaria|dominante|consolidada)|jurisprudencia\s+(?:constante|reiterada|pacÃ­fica))\b', re.I),
            'autoridad_reconocida': re.compile(r'\b(?:como\s+(?:bien\s+)?(?:seÃ±ala|indica|sostiene|afirma|enseÃ±a)|segÃºn\s+la\s+(?:opiniÃ³n|tesis)\s+de)\s+([A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±\s]+)\b', re.I)
        }
        
        # Verbos imperativos y de obligaciÃ³n
        self.verbos_imperativos = re.compile(
            r'\b(debe[rn]?|tiene[n]?\s+que|es\s+(?:necesario|obligatorio|imperativo|imprescindible)|'
            r'hay\s+que|corresponde|procede|cabe|resulta\s+(?:necesario|obligatorio))\b', 
            re.I
        )
        
        # Afirmaciones universales
        self.afirmaciones_universales = re.compile(
            r'\b(siempre|nunca|todos?|ningÃºn|jamÃ¡s|en\s+todos?\s+los\s+casos|'
            r'invariablemente|necesariamente|indudablemente|evidentemente)\b',
            re.I
        )
        
        # Adjetivos de valoraciÃ³n personal
        self.adjetivos_valorativos = re.compile(
            r'\b(importante|fundamental|esencial|crucial|relevante|significativo|'
            r'trascendental|decisivo|determinante|valioso|inadecuado|errÃ³neo|'
            r'incorrecto|acertado|correcto|apropiado|pertinente)\b',
            re.I
        )
        
        # Marcadores de Ã©nfasis
        self.marcadores_enfasis = re.compile(
            r'\b(muy|sumamente|extremadamente|altamente|especialmente|particularmente|'
            r'notablemente|significativamente|ciertamente|claramente|obviamente|'
            r'indiscutiblemente|sin\s+duda)\b',
            re.I
        )
        
        # Uso de "ejemplo/s"
        self.patron_ejemplos = re.compile(
            r'\b(por\s+ejemplo|v\.?\s*gr?\.?|verbigracia|asÃ­|tal\s+como|como\s+(?:ser|puede\s+verse)|'
            r'ejemplificando|a\s+modo\s+de\s+ejemplo|ilustrando)\b',
            re.I
        )
    
    def extraer_texto_completo(self, archivo_pdf: str, autoanalizar: bool = False) -> Optional[str]:
        """
        Extrae el texto completo de un PDF o TXT, con detecciÃ³n automÃ¡tica de tipo documental
        (sentencia vs doctrina), rutas absolutas o relativas compatibles con Windows y Linux,
        y opciÃ³n para anÃ¡lisis automÃ¡tico integrado con AnalizadorIntegralRAG.

        Args:
            archivo_pdf: Ruta absoluta o relativa al documento (.pdf o .txt)
            autoanalizar: Si True, realiza el anÃ¡lisis completo automÃ¡ticamente.

        Returns:
            str: Texto extraÃ­do limpio, o None si falla la lectura.
        """

        import os
        import re
        from pathlib import Path

        if not fitz:
            print("[!] PyMuPDF (fitz) no estÃ¡ disponible. Instalar con: pip install PyMuPDF")
            return None

        if not archivo_pdf or not isinstance(archivo_pdf, str):
            print("[!] No se proporcionÃ³ una ruta vÃ¡lida de archivo.")
            return None

        # ğŸ”§ 1ï¸âƒ£ Normalizar ruta para compatibilidad multiplataforma
        archivo_pdf = archivo_pdf.strip().replace("\\", "/")
        pdf_path = Path(archivo_pdf)

        # Si la ruta es absoluta, resolverla directamente
        posibles_rutas = []
        if pdf_path.is_absolute():
            posibles_rutas.append(pdf_path.expanduser().resolve())
        else:
            # Buscar en ubicaciones posibles
            posibles_rutas.extend([
                self.pdfs_path / pdf_path.name,
                self.pdfs_path / archivo_pdf,
                Path.cwd() / pdf_path.name,
                Path.cwd() / archivo_pdf
            ])

        # Buscar la primera ruta vÃ¡lida
        pdf_final = next((p for p in posibles_rutas if p.exists()), None)

        if not pdf_final:
            print(f"[!] No se encontrÃ³ el archivo: {archivo_pdf}")
            print(f"    ğŸ” Rutas probadas: {[str(p) for p in posibles_rutas]}")
            return None

        try:
            ext = pdf_final.suffix.lower()
            texto_completo = ""

            # ğŸ“˜ 2ï¸âƒ£ Leer segÃºn el tipo de archivo
            if ext == ".pdf":
                with fitz.open(str(pdf_final)) as doc:
                    texto_completo = "\n".join(page.get_text("text") for page in doc)

            elif ext == ".txt":
                with open(pdf_final, "r", encoding="utf-8", errors="ignore") as f:
                    texto_completo = f.read()

            else:
                print(f"[!] ExtensiÃ³n no soportada ({ext}). Se admite solo .pdf o .txt")
                return None

            # ğŸ§¹ 3ï¸âƒ£ Limpieza avanzada del texto
            texto_completo = re.sub(r"\s+", " ", texto_completo)
            texto_completo = texto_completo.replace("ï¬", "fi").replace("ï¬‚", "fl")
            texto_completo = texto_completo.replace("Â¬", "").replace("â€“", "-")
            texto_completo = texto_completo.strip()

            if not texto_completo or len(texto_completo) < 50:
                print(f"[!] No se pudo extraer texto legible de {pdf_final}")
                return None

            # âš–ï¸ 4ï¸âƒ£ DetecciÃ³n automÃ¡tica de tipo documental
            tipo_doc = "doctrina"
            patrones_sentencia = ["VISTO", "CONSIDERANDO", "RESUELVO", "FALLO", "AUTOS", "RESULTANDO"]
            if any(re.search(rf"\b{p}\b", texto_completo, re.IGNORECASE) for p in patrones_sentencia):
                tipo_doc = "sentencia"

            print(f"ğŸ“„ Documento detectado: {tipo_doc.upper()} â†’ {pdf_final.name}")

            # ğŸ§  5ï¸âƒ£ OpciÃ³n de anÃ¡lisis automÃ¡tico integrado
            if autoanalizar:
                try:
                    from colaborative.scripts.analizador_enriquecido_rag import AnalizadorIntegralRAGConMetadatos
                    analizador = AnalizadorIntegralRAGConMetadatos()
                    resultado = analizador.analizar_completo_texto(texto_completo, tipo=tipo_doc)
                    resultado["archivo"] = str(pdf_final)
                    print(f"âœ… AnÃ¡lisis completado: {pdf_final.name}")
                    return resultado
                except Exception as e:
                    print(f"[!] Error en anÃ¡lisis automÃ¡tico: {e}")
                    return texto_completo

            return texto_completo

        except Exception as e:
            print(f"[!] Error leyendo {pdf_final}: {e}")
            return None
    
    def extraer_autores_citados(self, texto: str) -> Dict[str, int]:
        """
        Extrae autores mencionados y cuenta frecuencias
        Returns: {nombre_autor: frecuencia}
        """
        if not texto:
            return {}
        
        # Lista de palabras a excluir (artÃ­culos, preposiciones, tÃ©rminos comunes)
        palabras_excluidas = {
            'el artÃ­culo', 'la ley', 'el contrato', 'el cual', 'el caso', 'la cual',
            'el presente', 'la presente', 'el mismo', 'la misma', 'los cuales',
            'las cuales', 'el autor', 'la autora', 'los autores', 'las autoras',
            'la doctrina', 'la jurisprudencia', 'el tribunal', 'la sentencia',
            'el ordenamiento', 'la normativa', 'el derecho', 'la obligaciÃ³n',
            'el juez', 'la corte', 'el juzgado', 'la sala', 'el consejo',
            'se trate', 'se debe', 'se puede', 'se refiere', 'se establece'
        }
        
        # Buscar patrones de citaciÃ³n acadÃ©mica
        patrones_cita = [
            # Formato: "segÃºn Nombre Apellido"
            r'segÃºn\s+([A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+(?:\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+){1,3})',
            # Formato: "Nombre Apellido sostiene/afirma/seÃ±ala"
            r'([A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+(?:\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+){1,3})\s+(?:sostiene|afirma|seÃ±ala|considera|expresa|indica|manifiesta|argumenta|plantea)',
            # Formato: "como indica Nombre Apellido"
            r'como\s+(?:indica|seÃ±ala|sostiene)\s+([A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+(?:\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+){1,3})',
            # Formato: "(Apellido, 2024)" - citas entre parÃ©ntesis
            r'\(([A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+(?:\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+){0,2}),\s*\d{4}\)',
            # Formato: "cfr. Nombre Apellido" o "v. Nombre Apellido"
            r'(?:cfr\.|cf\.|v\.|vid\.|vÃ©ase)\s+([A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+(?:\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+){1,3})',
            # Formato: "en opiniÃ³n de Nombre Apellido"
            r'en\s+opiniÃ³n\s+de\s+([A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+(?:\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+){1,3})',
            # Formato: "De Apellido" (nombres compuestos comunes)
            r'\b(De\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+(?:\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+){1,2})\b',
        ]
        
        autores_encontrados = []
        for patron in patrones_cita:
            matches = re.findall(patron, texto, re.UNICODE)
            autores_encontrados.extend(matches)
        
        # Contar frecuencias
        contador = Counter(autores_encontrados)
        
        # Filtrar nombres muy cortos, palabras excluidas y comunes
        filtrados = {}
        for nombre, freq in contador.items():
            nombre_limpio = nombre.strip()
            nombre_lower = nombre_limpio.lower()
            
            # Excluir si:
            # 1. Es muy corto (menos de 6 caracteres)
            # 2. EstÃ¡ en la lista de exclusiÃ³n
            # 3. Empieza con artÃ­culo ("el", "la", "los", "las")
            # 4. Solo aparece 1 vez (probablemente no es relevante)
            if (len(nombre_limpio) > 5 and 
                nombre_lower not in palabras_excluidas and
                not nombre_lower.startswith(('el ', 'la ', 'los ', 'las ', 'se ')) and
                freq > 1):
                filtrados[nombre_limpio] = freq
        
        return dict(sorted(filtrados.items(), key=lambda x: x[1], reverse=True))
    
    def extraer_palabras_clave(self, texto: str, top_n: int = 30) -> Dict[str, int]:
        """
        Extrae palabras clave jurÃ­dicas y su frecuencia
        Returns: {palabra: frecuencia}
        """
        if not texto:
            return {}
        
        texto_lower = texto.lower()
        palabras_encontradas = {}
        
        # Buscar tÃ©rminos jurÃ­dicos predefinidos
        for termino in self.terminos_juridicos:
            frecuencia = len(re.findall(r'\b' + re.escape(termino) + r'\b', texto_lower))
            if frecuencia > 0:
                palabras_encontradas[termino] = frecuencia
        
        # Buscar bigramas jurÃ­dicos comunes
        bigramas = re.findall(r'\b([a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+\s+[a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+)\b', texto_lower)
        contador_bigramas = Counter(bigramas)
        
        # Filtrar bigramas jurÃ­dicos (al menos 3 apariciones)
        for bigrama, freq in contador_bigramas.most_common(50):
            if freq >= 3 and any(term in bigrama for term in self.terminos_juridicos):
                palabras_encontradas[bigrama] = freq
        
        # Retornar top N
        return dict(sorted(palabras_encontradas.items(), key=lambda x: x[1], reverse=True)[:top_n])
    
    def detectar_posiciones_doctrinales(self, texto: str) -> Dict[str, List[str]]:
        """
        Detecta posicionamiento doctrinal del autor
        Returns: {tipo_posicion: [fragmentos_textuales]}
        """
        if not texto:
            return {}
        
        posiciones = {}
        
        for tipo, patron in self.patrones_posicion.items():
            matches = patron.finditer(texto)
            fragmentos = []
            
            for match in matches:
                # Extraer contexto (50 caracteres antes y despuÃ©s)
                start = max(0, match.start() - 50)
                end = min(len(texto), match.end() + 150)
                fragmento = texto[start:end].strip()
                fragmentos.append(fragmento)
            
            if fragmentos:
                posiciones[tipo] = fragmentos[:5]  # MÃ¡ximo 5 ejemplos por tipo
        
        return posiciones
    
    def calcular_estadisticas_avanzadas(self, texto: str) -> Dict:
        """Calcula estadÃ­sticas textuales avanzadas"""
        if not texto:
            return {}
        
        palabras = texto.split()
        oraciones = re.split(r'[.!?]+', texto)
        parrafos = texto.split('\n\n')
        
        return {
            'total_palabras': len(palabras),
            'total_oraciones': len([o for o in oraciones if len(o.strip()) > 10]),
            'total_parrafos': len([p for p in parrafos if len(p.strip()) > 50]),
            'promedio_palabras_oracion': len(palabras) / max(len(oraciones), 1),
            'promedio_palabras_parrafo': len(palabras) / max(len(parrafos), 1),
            'vocabulario_unico': len(set(palabras)),
            'riqueza_lexica': len(set(palabras)) / max(len(palabras), 1)
        }
    
    def analizar_marcadores_autoridad(self, texto: str) -> Dict:
        """Analiza marcadores que indican autoridad y peso argumentativo"""
        if not texto:
            return {}
        
        resultado = {
            'citas_libros': [],
            'citas_normas': [],
            'doctrina_establecida': [],
            'autoridad_reconocida': [],
            'total_marcadores': 0
        }
        
        # Citas de libros/artÃ­culos
        for match in self.marcadores_autoridad['cita_libro'].finditer(texto):
            resultado['citas_libros'].append({
                'texto': match.group(1)[:100],
                'autor': match.group(2),
                'aÃ±o': match.group(3)
            })
        
        # Citas normativas
        for match in self.marcadores_autoridad['cita_norma'].finditer(texto):
            resultado['citas_normas'].append({
                'tipo': match.group(1),
                'numero': match.group(2)
            })
        
        # Referencias a doctrina establecida
        resultado['doctrina_establecida'] = [
            match.group(0) 
            for match in self.marcadores_autoridad['doctrina_establecida'].finditer(texto)
        ]
        
        # Autoridades reconocidas
        for match in self.marcadores_autoridad['autoridad_reconocida'].finditer(texto):
            resultado['autoridad_reconocida'].append(match.group(1).strip())
        
        resultado['total_marcadores'] = (
            len(resultado['citas_libros']) +
            len(resultado['citas_normas']) +
            len(resultado['doctrina_establecida']) +
            len(resultado['autoridad_reconocida'])
        )
        
        return resultado
    
    def analizar_estilo_discursivo(self, texto: str) -> Dict:
        """Analiza el estilo discursivo: imperativos, afirmaciones, Ã©nfasis, valoraciones"""
        if not texto:
            return {}
        
        # Contar ocurrencias
        verbos_imperativos = self.verbos_imperativos.findall(texto)
        afirmaciones = self.afirmaciones_universales.findall(texto)
        adjetivos = self.adjetivos_valorativos.findall(texto)
        enfasis = self.marcadores_enfasis.findall(texto)
        ejemplos = self.patron_ejemplos.findall(texto)
        
        # Calcular densidad (por cada 100 palabras)
        total_palabras = len(texto.split())
        factor = 100.0 / max(total_palabras, 1)
        
        resultado = {
            'verbos_imperativos': {
                'total': len(verbos_imperativos),
                'densidad': len(verbos_imperativos) * factor,
                'mas_frecuentes': Counter(verbos_imperativos).most_common(5)
            },
            'afirmaciones_universales': {
                'total': len(afirmaciones),
                'densidad': len(afirmaciones) * factor,
                'mas_frecuentes': Counter(afirmaciones).most_common(5)
            },
            'adjetivos_valorativos': {
                'total': len(adjetivos),
                'densidad': len(adjetivos) * factor,
                'mas_frecuentes': Counter(adjetivos).most_common(10)
            },
            'marcadores_enfasis': {
                'total': len(enfasis),
                'densidad': len(enfasis) * factor,
                'mas_frecuentes': Counter(enfasis).most_common(5)
            },
            'uso_ejemplos': {
                'total': len(ejemplos),
                'densidad': len(ejemplos) * factor,
                'patrones': Counter(ejemplos).most_common(5)
            }
        }
        
        # Calcular Ã­ndice de asertividad (imperativo + universal + Ã©nfasis)
        resultado['indice_asertividad'] = (
            resultado['verbos_imperativos']['densidad'] +
            resultado['afirmaciones_universales']['densidad'] +
            resultado['marcadores_enfasis']['densidad']
        ) / 3.0
        
        # Calcular Ã­ndice de subjetividad (valoraciones + Ã©nfasis)
        resultado['indice_subjetividad'] = (
            resultado['adjetivos_valorativos']['densidad'] +
            resultado['marcadores_enfasis']['densidad']
        ) / 2.0
        
        return resultado
    
    def analizar_documento_completo(self, archivo_pdf: str, silent: bool = False) -> Dict:
        """
        AnÃ¡lisis completo del documento
        Args:
            archivo_pdf: Ruta al archivo PDF
            silent: Si es True, no imprime mensajes (util para Windows sin soporte emoji)
        Returns: Diccionario con toda la informaciÃ³n enriquecida
        """
        if not silent:
            print(f"[*] Analizando: {archivo_pdf}")
        
        texto = self.extraer_texto_completo(archivo_pdf)
        if not texto:
            return {}
        
        if not silent:
            print("  [*] Extrayendo autores citados...")
        autores_citados = self.extraer_autores_citados(texto)
        
        if not silent:
            print("  [*] Analizando palabras clave juridicas...")
        palabras_clave = self.extraer_palabras_clave(texto)
        
        if not silent:
            print("  [*] Detectando posicionamiento doctrinal...")
        posiciones = self.detectar_posiciones_doctrinales(texto)
        
        if not silent:
            print("  [*] Analizando marcadores de autoridad...")
        autoridad = self.analizar_marcadores_autoridad(texto)
        
        if not silent:
            print("  [*] Analizando estilo discursivo...")
        estilo = self.analizar_estilo_discursivo(texto)
        
        if not silent:
            print("  [*] Calculando estadisticas avanzadas...")
        stats = self.calcular_estadisticas_avanzadas(texto)
        
        if not silent:
            print("  [*] Analizando discernimiento cognitivo/retorico...")
        try:
            discernimiento = AnalizadorDiscernimientoRAG().analizar_discernimiento(texto)
        except Exception as e:
            if not silent:
                print(f"     [!] Error en analisis de discernimiento: {e}")
            discernimiento = {}
        
        # ANALISIS DE CONDUCTA JUDICIAL (Psicologia Judicial Aplicada)
        if not silent:
            print("  [*] Analizando conducta y decision judicial...")
        try:
            conducta_judicial = AnalizadorConductaJudicialRAG().analizar_conducta(texto)
        except Exception as e:
            if not silent:
                print(f"     [!] Error en analisis de conducta judicial: {e}")
            conducta_judicial = {}
        
        resultado = {
            'archivo': archivo_pdf,
            'autores_citados': autores_citados,
            'palabras_clave': palabras_clave,
            'posiciones_doctrinales': posiciones,
            'marcadores_autoridad': autoridad,
            'estilo_discursivo': estilo,
            'discernimiento': discernimiento,
            'conducta_judicial': conducta_judicial,  # ğŸ†• NUEVO
            'estadisticas': stats,
            'texto_completo_disponible': True
        }
        
        # Identificar autor mÃ¡s citado
        if resultado['autores_citados']:
            mas_citado = max(resultado['autores_citados'].items(), key=lambda x: x[1])
            resultado['autor_referencia_principal'] = {
                'nombre': mas_citado[0],
                'menciones': mas_citado[1]
            }
        
        return resultado


class AnalizadorDiscernimientoRAG:
    """
    ğŸ§  ANALIZADOR DE DISCERNIMIENTO COGNITIVO/RETÃ“RICO
    ===================================================
    
    Analiza criterios de discernimiento intelectual, Ã©tico, polÃ­tico y lÃ³gico.
    Se apoya en el anÃ¡lisis lingÃ¼Ã­stico para determinar:
    
    - LÃ³gica argumentativa (coherencia, tensiÃ³n dialÃ©ctica, resolutividad)
    - Discernimiento Ã©tico (juicio valorativo, equilibrio retÃ³rico)
    - Discernimiento jurÃ­dico (ratio decidendi, principialismo)
    - Discernimiento polÃ­tico/estratÃ©gico (pragmatismo, dogmatismo ideolÃ³gico)
    - AutopercepciÃ³n cognitiva (autoafirmaciÃ³n, reflexividad)
    
    Todas las mÃ©tricas estÃ¡n normalizadas por 1000 palabras.
    """
    
    def __init__(self, perfil: Optional[PerfilHeuristico] = None):
        self.perfil = perfil or PerfilHeuristico()
        
        # ğŸ” PATRONES PARA LÃ“GICA ARGUMENTATIVA
        self.conectores_condicionales = re.compile(
            r'\b(si|cuando|mientras|en\s+caso\s+de|de\s+modo\s+que|por\s+cuanto|'
            r'siempre\s+que|dado\s+que|puesto\s+que)\b', 
            re.I
        )
        
        self.conectores_concesivos = re.compile(
            r'\b(sin\s+embargo|aunque|no\s+obstante|a\s+pesar\s+de|pero|'
            r'pese\s+a|aun\s+cuando|si\s+bien)\b', 
            re.I
        )
        
        self.verbos_resolutivos = re.compile(
            r'\b(resuelve|dispone|determina|ordena|declara|concede|deniega|'
            r'establece|falla|sentencia|condena|absuelve)\b', 
            re.I
        )
        
        # ğŸ¯ PATRONES PARA DISCERNIMIENTO JURÃDICO
        self.verbos_normativos = re.compile(
            r'\b(regula|norma|prescribe|estipula|consagra|reconoce|garantiza|'
            r'protege|tutela|ampara)\b', 
            re.I
        )
        
        self.principialismo = re.compile(
            r'\b(principio|valor|finalidad|proporcionalidad|justicia|razonabilidad|'
            r'equidad|axiologÃ­a|teleologÃ­a|bien\s+jurÃ­dico)\b', 
            re.I
        )
        
        # ğŸ’¼ PATRONES PARA DISCERNIMIENTO POLÃTICO/ESTRATÃ‰GICO
        self.verbos_pragmaticos = re.compile(
            r'\b(aplica|ejecuta|negocia|gestiona|implementa|propone|actÃºa|'
            r'desarrolla|concreta|materializa|instrumenta)\b', 
            re.I
        )
        
        self.ideologemas = re.compile(
            r'\b(siempre\s+se\s+debe|nunca\s+se\s+puede|es\s+evidente\s+que|'
            r'no\s+cabe\s+duda|resulta\s+claro|es\s+indiscutible)\b', 
            re.I
        )
        
        # ğŸ¤” PATRONES PARA AUTOPERCEPCIÃ“N COGNITIVA
        self.reflexividad = re.compile(
            r'\b(puede\s+verse|parecerÃ­a|cabe\s+preguntarse|conviene\s+analizar|'
            r'no\s+es\s+claro|podrÃ­a|eventualmente|posiblemente|quizÃ¡s?)\b', 
            re.I
        )
        
        self.pronombres_personales = re.compile(
            r'\b(yo|mi|me|mÃ­o|nosotros|nuestro|nuestra|nos)\b', 
            re.I
        )
        
        # ğŸ“Š PATRONES PARA JUICIO VALORATIVO
        self.adjetivos_etico_morales = re.compile(
            r'\b(justo|injusto|legÃ­timo|ilegÃ­timo|correcto|incorrecto|'
            r'apropiado|inapropiado|Ã©tico|inmoral|razonable|irrazonable|'
            r'prudente|imprudente|adecuado|inadecuado)\b', 
            re.I
        )
    
    def _dens(self, n: int, total_palabras: int) -> float:
        """Calcula densidad normalizada por 1000 palabras"""
        return (n * 1000.0) / max(total_palabras, 1)
    
    def analizar_discernimiento(self, texto: str) -> Dict[str, float]:
        """
        AnÃ¡lisis completo de discernimiento cognitivo/retÃ³rico
        Returns: Dict con todas las mÃ©tricas normalizadas
        """
        if not texto:
            return {}
        
        total_palabras = len(texto.split())
        
        # ğŸ” LÃ“GICA ARGUMENTATIVA
        condicionales = len(self.conectores_condicionales.findall(texto))
        concesivos = len(self.conectores_concesivos.findall(texto))
        resolutivos = len(self.verbos_resolutivos.findall(texto))
        
        # ğŸ¯ DISCERNIMIENTO JURÃDICO
        normativos = len(self.verbos_normativos.findall(texto))
        principios = len(self.principialismo.findall(texto))
        
        # ğŸ’¼ DISCERNIMIENTO POLÃTICO/ESTRATÃ‰GICO
        pragmaticos = len(self.verbos_pragmaticos.findall(texto))
        ideologicos = len(self.ideologemas.findall(texto))
        
        # ğŸ¤” AUTOPERCEPCIÃ“N COGNITIVA
        reflexivos = len(self.reflexividad.findall(texto))
        personales = len(self.pronombres_personales.findall(texto))
        
        # ğŸ“Š JUICIO VALORATIVO
        valorativos = len(self.adjetivos_etico_morales.findall(texto))
        
        # Calcular densidades
        metricas = {
            # LÃ³gica Argumentativa
            'coherencia_interna': self._dens(condicionales, total_palabras),
            'tension_dialectica': self._dens(concesivos, total_palabras),
            'resolutividad': self._dens(resolutivos, total_palabras),
            
            # Discernimiento JurÃ­dico
            'ratio_decidendi': self._dens(normativos, total_palabras),
            'principialismo': self._dens(principios, total_palabras),
            
            # Discernimiento PolÃ­tico/EstratÃ©gico
            'pragmatismo': self._dens(pragmaticos, total_palabras),
            'dogmatismo_ideologico': self._dens(ideologicos, total_palabras),
            
            # AutopercepciÃ³n Cognitiva
            'reflexividad': self._dens(reflexivos, total_palabras),
            'autoafirmacion': self._dens(personales, total_palabras),
            
            # Discernimiento Ã‰tico
            'juicio_valorativo': self._dens(valorativos, total_palabras),
        }
        
        # ğŸ“ˆ ÃNDICES DERIVADOS (usando pesos del perfil heurÃ­stico)
        p = self.perfil
        
        # Dogmatismo general (coherencia + resolutividad - tensiÃ³n dialÃ©ctica)
        metricas['dogmatismo_general'] = (
            metricas['coherencia_interna'] * p.w_coherencia +
            metricas['resolutividad'] * p.w_resolutividad -
            metricas['tension_dialectica'] * p.w_tension
        )
        
        # Discernimiento prudencial (tensiÃ³n + reflexividad + principios)
        metricas['discernimiento_prudencial'] = (
            metricas['tension_dialectica'] * p.w_tension_pru +
            metricas['reflexividad'] * p.w_reflexividad_pru +
            metricas['principialismo'] * p.w_principialismo_pru
        )
        
        # Equilibrio retÃ³rico (relaciÃ³n entre crÃ­tica y afirmaciÃ³n)
        # Alto concesivo + bajo ideolÃ³gico = equilibrado
        metricas['equilibrio_retorico'] = (
            metricas['tension_dialectica'] - 
            metricas['dogmatismo_ideologico']
        )
        
        # Clasificar perfil general
        metricas['perfil_general'] = self._clasificar_perfil(metricas)
        
        return metricas
    
    def _clasificar_perfil(self, m: Dict[str, float]) -> str:
        """
        Clasifica el perfil intelectual general basÃ¡ndose en las mÃ©tricas
        
        Perfiles posibles:
        - DogmÃ¡tico-normativo: Alta coherencia, baja tensiÃ³n
        - Reflexivo-principialista: Alta reflexividad y principialismo
        - PragmÃ¡tico-ejecutivo: Alto pragmatismo y resolutividad
        - CrÃ­tico-analÃ­tico: Alta tensiÃ³n dialÃ©ctica
        - Balanceado: Sin predominancia clara
        """
        
        # Reglas de clasificaciÃ³n (ajustables)
        if m['dogmatismo_general'] > 2.0 and m['tension_dialectica'] < 1.0:
            return "DogmÃ¡tico-normativo"
        
        if m['reflexividad'] > 2.0 and m['principialismo'] > 1.5:
            return "Reflexivo-principialista"
        
        if m['pragmatismo'] > 2.0 and m['resolutividad'] > 2.0:
            return "PragmÃ¡tico-ejecutivo"
        
        if m['tension_dialectica'] > 2.5:
            return "CrÃ­tico-analÃ­tico"
        
        if m['ratio_decidendi'] > 2.5 and m['coherencia_interna'] > 2.0:
            return "TÃ©cnico-jurÃ­dico"
        
        if m['juicio_valorativo'] > 2.0 and m['principialismo'] > 2.0:
            return "AxiolÃ³gico-valorativo"
        
        return "Balanceado"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§  MÃ“DULO DE PSICOLOGÃA JUDICIAL APLICADA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AnalizadorConductaJudicialRAG:
    """
    ğŸ¯ ANALIZADOR DE CONDUCTA Y DECISIÃ“N JUDICIAL
    
    Analiza el comportamiento intelectual, emocional y decisional del juez 
    o autor jurÃ­dico a partir de patrones lingÃ¼Ã­sticos, estructuras lÃ³gicas 
    y elecciones de vocabulario.
    
    ğŸ“Š DIMENSIONES ANALIZADAS:
    1. Cognitiva: Racionalidad jurÃ­dica y estructura mental
    2. Emocional: Tono, empatÃ­a, irritaciÃ³n, prudencia
    3. Decisional: Estilo resolutivo, consistencia, proporcionalidad
    4. Valorativa: Justicia, Ã©tica, derechos humanos, poder
    
    Permite detectar CÃ“MO DECIDE, CÃ“MO RAZONA y CÃ“MO SE EXPRESA un juez
    con precisiÃ³n analÃ­tica y trazabilidad cuantitativa.
    """
    
    def __init__(self):
        # ğŸ” PATRONES LINGÃœÃSTICOS CLAVE PARA CONDUCTA JUDICIAL
        
        # Autoridad institucional (invocaciÃ³n al poder judicial)
        self.patron_autoridad = re.compile(
            r'\b(el\s+tribunal|esta\s+sala|este\s+juzgado|se\s+resuelve|'
            r'se\s+dispone|se\s+declara|esta\s+magistratura|este\s+Ã³rgano)\b',
            re.IGNORECASE
        )
        
        # EmpatÃ­a humanista (sensibilidad hacia personas)
        self.patron_empatia = re.compile(
            r'\b(vulnerable|dignidad|humanidad|sufrimiento|equidad|'
            r'empat[iÃ­]a|atento\s+a|comprensi[oÃ³]n|situaci[oÃ³]n\s+personal|'
            r'contexto\s+vital|realidad\s+de)\b',
            re.IGNORECASE
        )
        
        # IrritaciÃ³n/tono negativo (emotividad reactiva)
        self.patron_irritacion = re.compile(
            r'\b(inaceptable|inadmisible|repudia|grave|escandaloso|'
            r'irregular|falta\s+de\s+respeto|abuso|negligente|'
            r'intolerable|censurable|reprochable)\b',
            re.IGNORECASE
        )
        
        # Proporcionalidad (equilibrio y ponderaciÃ³n)
        self.patron_proporcionalidad = re.compile(
            r'\b(proporcional|razonable|equilibrado|ponderado|moderado|'
            r'en\s+justa\s+medida|adecuado|balance|sopesar|ponderar)\b',
            re.IGNORECASE
        )
        
        # Referencia a derechos (orientaciÃ³n Ã©tica-garantista)
        self.patron_derechos = re.compile(
            r'\b(derechos\s+humanos|garant[iÃ­]as|igualdad|'
            r'no\s+discriminaci[oÃ³]n|debido\s+proceso|justicia|'
            r'derechos\s+fundamentales|convencionalidad|tutela\s+efectiva)\b',
            re.IGNORECASE
        )
        
        # Formalismo jurÃ­dico (apego a la norma textual)
        self.patron_formalismo = re.compile(
            r'\b(conforme\s+a|seg[uÃº]n\s+lo\s+previsto|art[iÃ­]culo|'
            r'ley\s+n[Ãºu]m|disposici[oÃ³]n|norma|c[oÃ³]digo|literal|'
            r'textualmente|expresamente)\b',
            re.IGNORECASE
        )
        
        # MitigaciÃ³n retÃ³rica (concesiones, matices)
        self.patron_mitigacion = re.compile(
            r'\b(sin\s+perjuicio\s+de|sin\s+embargo|a\s+pesar\s+de|'
            r'no\s+obstante|si\s+bien|aun\s+cuando|aunque)\b',
            re.IGNORECASE
        )
        
        # Autocontrol discursivo (prudencia, mesura)
        self.patron_autocontrol = re.compile(
            r'\b(cautela|prudencia|mesura|considera|pondera|'
            r'eval[uÃº]a|examina|analiza|reflexiona|medita)\b',
            re.IGNORECASE
        )
    
    def analizar_conducta(self, texto: str) -> Dict[str, float]:
        """
        AnÃ¡lisis completo de conducta judicial.
        Retorna mÃ©tricas normalizadas por 1000 palabras + perfil decisional.
        """
        if not texto or len(texto) < 100:
            return {
                "error": "Texto insuficiente para anÃ¡lisis de conducta",
                "perfil_decisional": "No determinado"
            }
        
        total_palabras = len(texto.split())
        factor = 1000.0 / max(total_palabras, 1)
        
        # ğŸ“Š CONTEO DE PATRONES
        c_autoridad = len(self.patron_autoridad.findall(texto))
        c_empatia = len(self.patron_empatia.findall(texto))
        c_irritacion = len(self.patron_irritacion.findall(texto))
        c_proporcionalidad = len(self.patron_proporcionalidad.findall(texto))
        c_derechos = len(self.patron_derechos.findall(texto))
        c_formalismo = len(self.patron_formalismo.findall(texto))
        c_mitigacion = len(self.patron_mitigacion.findall(texto))
        c_autocontrol = len(self.patron_autocontrol.findall(texto))
        
        # ğŸ“ˆ MÃ‰TRICAS BASE (normalizadas por 1000 palabras)
        resultados = {
            # DimensiÃ³n institucional
            "autoridad_institucional": c_autoridad * factor,
            
            # DimensiÃ³n emocional
            "empatia_humanista": c_empatia * factor,
            "tono_irritativo": c_irritacion * factor,
            "autocontrol_discursivo": c_autocontrol * factor,
            
            # DimensiÃ³n argumentativa
            "proporcionalidad_argumental": c_proporcionalidad * factor,
            "mitigacion_retorica": c_mitigacion * factor,
            
            # DimensiÃ³n valorativa
            "referencia_derechos": c_derechos * factor,
            "formalismo_juridico": c_formalismo * factor,
        }
        
        # ğŸ§® ÃNDICES DERIVADOS COMPLEJOS
        
        # Equilibrio emocional (autocontrol + ponderaciÃ³n - irritaciÃ³n)
        resultados["equilibrio_emocional"] = (
            (resultados["autocontrol_discursivo"] + 
             resultados["proporcionalidad_argumental"]) -
            resultados["tono_irritativo"]
        )
        
        # PredisposiciÃ³n humanista (empatÃ­a + derechos humanos)
        resultados["predisposicion_humanista"] = (
            resultados["empatia_humanista"] + 
            resultados["referencia_derechos"]
        ) / 2.0
        
        # OrientaciÃ³n normativa vs eticidad
        # Positivo = mÃ¡s formalista, Negativo = mÃ¡s axiolÃ³gico
        resultados["orientacion_normativa_vs_eticidad"] = (
            resultados["formalismo_juridico"] - 
            resultados["referencia_derechos"]
        )
        
        # Ãndice de templanza judicial (mitigaciÃ³n + autocontrol - irritaciÃ³n)
        resultados["templanza_judicial"] = (
            resultados["mitigacion_retorica"] + 
            resultados["autocontrol_discursivo"] -
            resultados["tono_irritativo"]
        )
        
        # ğŸ† CLASIFICACIÃ“N DE PERFIL DECISIONAL
        resultados["perfil_decisional"] = self._clasificar_decision(resultados)
        
        return resultados
    
    def _clasificar_decision(self, r: Dict[str, float]) -> str:
        """
        Clasifica el tipo de pensamiento decisional del juez/autor:
        
        - TÃ©cnico-formalista: Apegado a la ley, riguroso, textualista
        - Ã‰tico-garantista: Orientado a derechos, protecciÃ³n de garantÃ­as
        - Autoritario-reactivo: Tono fuerte, irritable, impositivo
        - Prudente-equilibrado: Ponderado, mesurado, balanceado
        - Emotivo-humanista: EmpÃ¡tico, sensible, contextualizado
        - Mixto o indefinido: Sin predominancia clara
        """
        
        # Reglas de clasificaciÃ³n basadas en umbrales empÃ­ricos
        
        # TÃ©cnico-formalista: Alto formalismo + Baja referencia a derechos
        if r["formalismo_juridico"] > 4.0 and r["referencia_derechos"] < 1.0:
            return "TÃ©cnico-formalista"
        
        # Emotivo-humanista: Alta empatÃ­a + Bajo formalismo
        if r["predisposicion_humanista"] > 3.0 and r["formalismo_juridico"] < 2.0:
            return "Emotivo-humanista"
        
        # Autoritario-reactivo: Alto tono irritativo + Bajo autocontrol
        if r["tono_irritativo"] > 3.0 and r["autocontrol_discursivo"] < 1.0:
            return "Autoritario-reactivo"
        
        # Prudente-equilibrado: Alto equilibrio emocional + Alta proporcionalidad
        if r["equilibrio_emocional"] > 3.0 and r["proporcionalidad_argumental"] > 2.0:
            return "Prudente-equilibrado"
        
        # Ã‰tico-garantista: Alta referencia a derechos + Alto formalismo
        # (combina normatividad con valores)
        if r["referencia_derechos"] > 3.0 and r["formalismo_juridico"] > 2.0:
            return "Ã‰tico-garantista"
        
        # Normativo-moderado: Formalismo moderado sin extremos
        if 2.0 < r["formalismo_juridico"] < 4.0 and r["tono_irritativo"] < 1.5:
            return "Normativo-moderado"
        
        return "Mixto o indefinido"


def probar_analizador():
    """FunciÃ³n de prueba"""
    analizador = AnalizadorEnriquecidoRAG()
    
    # Buscar PDF de ejemplo
    conn = sqlite3.connect('colaborative/bases_rag/cognitiva/metadatos.db')
    c = conn.cursor()
    c.execute('SELECT archivo FROM perfiles_cognitivos WHERE autor LIKE ? LIMIT 1', ('%CARLOS%',))
    result = c.fetchone()
    conn.close()
    
    if result and result[0]:
        print(f"\nğŸ“„ Probando con: {result[0]}\n")
        analisis = analizador.analizar_documento_completo(result[0])
        
        print("\n" + "="*70)
        print("ğŸ“Š RESULTADOS DEL ANÃLISIS ENRIQUECIDO")
        print("="*70)
        
        if analisis.get('autores_citados'):
            print("\nğŸ‘¥ AUTORES CITADOS (Top 10):")
            for autor, freq in list(analisis['autores_citados'].items())[:10]:
                print(f"   â€¢ {autor}: {freq} menciones")
        
        if analisis.get('palabras_clave'):
            print("\nğŸ”‘ PALABRAS CLAVE JURÃDICAS (Top 15):")
            for palabra, freq in list(analisis['palabras_clave'].items())[:15]:
                print(f"   â€¢ {palabra}: {freq} veces")
        
        if analisis.get('autor_referencia_principal'):
            ref = analisis['autor_referencia_principal']
            print(f"\nâ­ AUTOR DE REFERENCIA PRINCIPAL:")
            print(f"   {ref['nombre']} ({ref['menciones']} menciones)")
        
        if analisis.get('estadisticas'):
            stats = analisis['estadisticas']
            print(f"\nğŸ“ˆ ESTADÃSTICAS:")
            print(f"   â€¢ Total palabras: {stats['total_palabras']:,}")
            print(f"   â€¢ Total oraciones: {stats['total_oraciones']}")
            print(f"   â€¢ Palabras/oraciÃ³n: {stats['promedio_palabras_oracion']:.1f}")
            print(f"   â€¢ Vocabulario Ãºnico: {stats['vocabulario_unico']:,}")
            print(f"   â€¢ Riqueza lÃ©xica: {stats['riqueza_lexica']:.3f}")
        
        if analisis.get('posiciones_doctrinales'):
            print(f"\nğŸ“ POSICIONES DOCTRINALES:")
            for tipo, fragmentos in analisis['posiciones_doctrinales'].items():
                print(f"   â€¢ {tipo.upper()}: {len(fragmentos)} instancias")
                if fragmentos:
                    print(f"     Ejemplo: '{fragmentos[0][:100]}...'")
        
        # NUEVOS ANÃLISIS
        if analisis.get('marcadores_autoridad'):
            autoridad = analisis['marcadores_autoridad']
            print(f"\nğŸ¯ MARCADORES DE AUTORIDAD:")
            print(f"   â€¢ Total marcadores: {autoridad.get('total_marcadores', 0)}")
            
            if autoridad.get('citas_libros'):
                print(f"\n   ğŸ“š Citas de libros/artÃ­culos: {len(autoridad['citas_libros'])}")
                for cita in autoridad['citas_libros'][:3]:
                    print(f"      - {cita['autor']} ({cita['aÃ±o']}): \"{cita['texto']}...\"")
            
            if autoridad.get('citas_normas'):
                print(f"\n   âš–ï¸ Citas normativas: {len(autoridad['citas_normas'])}")
                normas_contador = Counter([f"{c['tipo']} {c['numero']}" for c in autoridad['citas_normas']])
                for norma, freq in normas_contador.most_common(5):
                    print(f"      - {norma}: {freq} veces")
            
            if autoridad.get('doctrina_establecida'):
                print(f"\n   ğŸ“– Referencias a doctrina establecida: {len(autoridad['doctrina_establecida'])}")
                for ref in autoridad['doctrina_establecida'][:3]:
                    print(f"      - \"{ref}\"")
            
            if autoridad.get('autoridad_reconocida'):
                print(f"\n   â­ Autoridades reconocidas: {len(set(autoridad['autoridad_reconocida']))}")
                for aut in list(set(autoridad['autoridad_reconocida']))[:5]:
                    print(f"      - {aut}")
        
        if analisis.get('estilo_discursivo'):
            estilo = analisis['estilo_discursivo']
            print(f"\nğŸ’¬ ESTILO DISCURSIVO:")
            
            print(f"\n   ğŸ”¹ Verbos Imperativos:")
            print(f"      Total: {estilo['verbos_imperativos']['total']}")
            print(f"      Densidad: {estilo['verbos_imperativos']['densidad']:.2f} por 100 palabras")
            if estilo['verbos_imperativos']['mas_frecuentes']:
                print(f"      MÃ¡s usados: {', '.join([f'{v} ({c})' for v, c in estilo['verbos_imperativos']['mas_frecuentes'][:3]])}")
            
            print(f"\n   ğŸ”¹ Afirmaciones Universales:")
            print(f"      Total: {estilo['afirmaciones_universales']['total']}")
            print(f"      Densidad: {estilo['afirmaciones_universales']['densidad']:.2f} por 100 palabras")
            if estilo['afirmaciones_universales']['mas_frecuentes']:
                print(f"      MÃ¡s usados: {', '.join([f'{v} ({c})' for v, c in estilo['afirmaciones_universales']['mas_frecuentes'][:3]])}")
            
            print(f"\n   ğŸ”¹ Adjetivos Valorativos:")
            print(f"      Total: {estilo['adjetivos_valorativos']['total']}")
            print(f"      Densidad: {estilo['adjetivos_valorativos']['densidad']:.2f} por 100 palabras")
            if estilo['adjetivos_valorativos']['mas_frecuentes']:
                print(f"      MÃ¡s usados: {', '.join([f'{v} ({c})' for v, c in estilo['adjetivos_valorativos']['mas_frecuentes'][:5]])}")
            
            print(f"\n   ğŸ”¹ Marcadores de Ã‰nfasis:")
            print(f"      Total: {estilo['marcadores_enfasis']['total']}")
            print(f"      Densidad: {estilo['marcadores_enfasis']['densidad']:.2f} por 100 palabras")
            
            print(f"\n   ğŸ”¹ Uso de Ejemplos:")
            print(f"      Total: {estilo['uso_ejemplos']['total']}")
            print(f"      Densidad: {estilo['uso_ejemplos']['densidad']:.2f} por 100 palabras")
            if estilo['uso_ejemplos']['patrones']:
                print(f"      Patrones: {', '.join([f'{v} ({c})' for v, c in estilo['uso_ejemplos']['patrones'][:3]])}")
            
            print(f"\n   ğŸ“Š ÃNDICES CALCULADOS:")
            print(f"      â€¢ Ãndice de Asertividad: {estilo['indice_asertividad']:.2f}")
            print(f"      â€¢ Ãndice de Subjetividad: {estilo['indice_subjetividad']:.2f}")
        
        if analisis.get('discernimiento'):
            d = analisis['discernimiento']
            print(f"\nğŸ§  ANÃLISIS DE DISCERNIMIENTO COGNITIVO/RETÃ“RICO:")
            print(f"   (MÃ©tricas por 1000 palabras)")
            
            print(f"\n   ğŸ” LÃ³gica Argumentativa:")
            print(f"      â€¢ Coherencia interna: {d.get('coherencia_interna', 0):.2f}")
            print(f"      â€¢ TensiÃ³n dialÃ©ctica: {d.get('tension_dialectica', 0):.2f}")
            print(f"      â€¢ Resolutividad: {d.get('resolutividad', 0):.2f}")
            
            print(f"\n   ğŸ¯ Discernimiento JurÃ­dico:")
            print(f"      â€¢ Ratio decidendi: {d.get('ratio_decidendi', 0):.2f}")
            print(f"      â€¢ Principialismo: {d.get('principialismo', 0):.2f}")
            
            print(f"\n   ğŸ’¼ Discernimiento PolÃ­tico/EstratÃ©gico:")
            print(f"      â€¢ Pragmatismo: {d.get('pragmatismo', 0):.2f}")
            print(f"      â€¢ Dogmatismo ideolÃ³gico: {d.get('dogmatismo_ideologico', 0):.2f}")
            
            print(f"\n   ğŸ¤” AutopercepciÃ³n Cognitiva:")
            print(f"      â€¢ Reflexividad: {d.get('reflexividad', 0):.2f}")
            print(f"      â€¢ AutoafirmaciÃ³n: {d.get('autoafirmacion', 0):.2f}")
            
            print(f"\n   ğŸ“Š Discernimiento Ã‰tico:")
            print(f"      â€¢ Juicio valorativo: {d.get('juicio_valorativo', 0):.2f}")
            
            print(f"\n   ğŸ­ ÃNDICES DERIVADOS:")
            print(f"      â€¢ Dogmatismo general: {d.get('dogmatismo_general', 0):.2f}")
            print(f"      â€¢ Discernimiento prudencial: {d.get('discernimiento_prudencial', 0):.2f}")
            print(f"      â€¢ Equilibrio retÃ³rico: {d.get('equilibrio_retorico', 0):.2f}")
            
            perfil = d.get('perfil_general', 'No determinado')
            print(f"\n   ğŸ† PERFIL INTELECTUAL GENERAL: {perfil}")
        
        # ğŸ†• MÃ“DULO DE PSICOLOGÃA JUDICIAL APLICADA
        if analisis.get('conducta_judicial'):
            cj = analisis['conducta_judicial']
            print(f"\n{'='*70}")
            print(f"âš–ï¸ PSICOLOGÃA JUDICIAL APLICADA - CONDUCTA Y DECISIÃ“N")
            print(f"{'='*70}")
            print(f"   (MÃ©tricas normalizadas por 1000 palabras)\n")
            
            print(f"   ğŸ›ï¸ DIMENSIÃ“N INSTITUCIONAL:")
            print(f"      â€¢ Autoridad institucional: {cj.get('autoridad_institucional', 0):.2f}")
            print(f"        â†³ InvocaciÃ³n al poder judicial y funciÃ³n institucional")
            
            print(f"\n   ğŸ’š DIMENSIÃ“N EMOCIONAL:")
            print(f"      â€¢ EmpatÃ­a humanista: {cj.get('empatia_humanista', 0):.2f}")
            print(f"        â†³ Sensibilidad hacia personas y situaciones vitales")
            print(f"      â€¢ Tono irritativo: {cj.get('tono_irritativo', 0):.2f}")
            print(f"        â†³ Lenguaje reactivo, condenatorio o autoritario")
            print(f"      â€¢ Autocontrol discursivo: {cj.get('autocontrol_discursivo', 0):.2f}")
            print(f"        â†³ Control emocional y racionalidad en la expresiÃ³n")
            
            print(f"\n   âš–ï¸ DIMENSIÃ“N ARGUMENTATIVA:")
            print(f"      â€¢ Proporcionalidad argumental: {cj.get('proporcionalidad_argumental', 0):.2f}")
            print(f"        â†³ Equilibrio y ponderaciÃ³n en razonamientos")
            print(f"      â€¢ MitigaciÃ³n retÃ³rica: {cj.get('mitigacion_retorica', 0):.2f}")
            print(f"        â†³ Uso de concesiones y matices ('sin embargo', 'no obstante')")
            
            print(f"\n   ğŸ“œ DIMENSIÃ“N VALORATIVA:")
            print(f"      â€¢ Referencia a derechos: {cj.get('referencia_derechos', 0):.2f}")
            print(f"        â†³ InclusiÃ³n de derechos humanos y garantÃ­as")
            print(f"      â€¢ Formalismo jurÃ­dico: {cj.get('formalismo_juridico', 0):.2f}")
            print(f"        â†³ Apego a la norma textual y legalismo")
            
            print(f"\n   ğŸ“Š ÃNDICES DERIVADOS:")
            eq_em = cj.get('equilibrio_emocional', 0)
            print(f"      â€¢ Equilibrio emocional: {eq_em:.2f}")
            interp_eq = "ğŸŸ¢ Alto" if eq_em > 3 else "ğŸŸ¡ Moderado" if eq_em > 1 else "ğŸ”´ Bajo"
            print(f"        â†³ (Autocontrol + PonderaciÃ³n âˆ’ IrritaciÃ³n) = {interp_eq}")
            
            pred_h = cj.get('predisposicion_humanista', 0)
            print(f"      â€¢ PredisposiciÃ³n humanista: {pred_h:.2f}")
            interp_ph = "ğŸŸ¢ Alta" if pred_h > 3 else "ğŸŸ¡ Moderada" if pred_h > 1 else "ğŸ”´ Baja"
            print(f"        â†³ (EmpatÃ­a + Derechos humanos) / 2 = {interp_ph}")
            
            orient = cj.get('orientacion_normativa_vs_eticidad', 0)
            print(f"      â€¢ OrientaciÃ³n normativa vs eticidad: {orient:.2f}")
            interp_or = "âš–ï¸ Legalista" if orient > 2 else "âš–ï¸ AxiolÃ³gico" if orient < -2 else "âš–ï¸ Balanceado"
            print(f"        â†³ (Formalismo âˆ’ Derechos) = {interp_or}")
            
            temp = cj.get('templanza_judicial', 0)
            print(f"      â€¢ Templanza judicial: {temp:.2f}")
            interp_te = "ğŸŸ¢ Alta" if temp > 3 else "ğŸŸ¡ Moderada" if temp > 1 else "ğŸ”´ Baja"
            print(f"        â†³ (MitigaciÃ³n + Autocontrol âˆ’ IrritaciÃ³n) = {interp_te}")
            
            perfil_dec = cj.get('perfil_decisional', 'No determinado')
            print(f"\n   ğŸ† PERFIL DECISIONAL: {perfil_dec}")
            print(f"      â†³ Tipo de razonamiento y conducta judicial predominante\n")
    else:
        print("âŒ No se encontrÃ³ PDF para analizar")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# âš–ï¸ SISTEMA COGNITIVO JURÃDICO â€“ PARCHE INTEGRAL
# Autor: Dr. Pablo N. FarÃ­as
# Fecha: 2025-11-11
# MÃ³dulo: analizador_enriquecido_rag.py
# Funciones:
#   â€¢ AnÃ¡lisis argumentativo (razonamiento, falacias, fuerza argumental)
#   â€¢ IntegraciÃ³n con estructura judicial (VISTO, CONSIDERANDO, RESUELVO)
#   â€¢ ConexiÃ³n con metadatos de doctrina y sentencias (JSON unificado)
#   â€¢ Lectura directa desde PDF/TXT o bases RAG
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import os

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# UTILIDADES DE ENTRADA
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _leer_texto_desde_pdf(ruta_pdf: str) -> str:
    """Extrae texto de PDF usando PyMuPDF (fitz)."""
    try:
        import fitz
    except Exception:
        return ""
    try:
        doc = fitz.open(ruta_pdf)
        texto = "\n".join(page.get_text() for page in doc)
        doc.close()
        return texto
    except Exception:
        return ""


def _leer_texto_fallback(ruta: str) -> str:
    """Lee texto plano o PDF; retorna vacÃ­o si falla."""
    if not os.path.exists(ruta):
        return ""
    ext = os.path.splitext(ruta)[1].lower()
    if ext == ".txt":
        try:
            with open(ruta, "r", encoding="utf-8", errors="ignore") as f:
                return f.read()
        except Exception:
            return ""
    if ext == ".pdf":
        return _leer_texto_desde_pdf(ruta)
    return ""


def _recuperar_texto_desde_base_stub(ruta_pdf: str) -> str:
    """Stub para integraciÃ³n RAG; reemplazar con funciÃ³n real."""
    return ""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ANALIZADOR ARGUMENTATIVO JURÃDICO
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class AnalizadorArgumentativoJuridico:
    """Detecta falacias, tipo de razonamiento y fuerza argumental."""

    def __init__(self):
        self.patrones_falacias = {
            "ad_hominem": r"(no\s+es\s+creÃ­ble\s+porque|su\s+conducta|carece\s+de\s+autoridad)",
            "ad_populum": r"(todo\s+el\s+mundo\s+sabe|es\s+evidente\s+para\s+todos)",
            "petitio_principii": r"(porque\s+es\s+asÃ­|ya\s+que\s+es\s+cierto\s+que)",
            "ad_authoritatem": r"(segÃºn\s+(la\s+CSJN|la\s+Corte|el\s+autor)|como\s+dijo)",
            "falsa_causa": r"(despuÃ©s\s+de\s+que\s+ocurriÃ³|por\s+haber\s+ocurrido)",
            "falsa_dicotomia": r"(no\s+hay\s+otra\s+opciÃ³n|solo\s+existen\s+dos\s+posibilidades)",
            "apelacion_a_la_emocion": r"(injusto\s+para\s+las\s+vÃ­ctimas|cruel|indignante)",
            "non_sequitur": r"(no\s+se\s+sigue\s+lÃ³gicamente|sin\s+fundamento\s+lÃ³gico)"
        }
        self.patrones_razonamiento = {
            "deductivo": r"(por\s+tanto|en\s+consecuencia|se\s+sigue\s+que)",
            "inductivo": r"(en\s+muchos\s+casos|se\s+observa\s+que)",
            "analÃ³gico": r"(asÃ­\s+como|del\s+mismo\s+modo|anÃ¡logamente)",
            "axiolÃ³gico": r"(justicia|equidad|razonabilidad|valor)",
            "pragmÃ¡tico": r"(en\s+la\s+prÃ¡ctica|eficacia|conveniencia)"
        }
        self.tipo_argumento_juridico = {
            "normativo": r"(art\.|artÃ­culo|ley\s+\d+|c[oÃ³]digo|constituciÃ³n)",
            "axiolÃ³gico": r"(principio|valor|razonabilidad|teleologÃ­a)",
            "fÃ¡ctico": r"(hecho|prueba|evidencia|testimonio|pericia)",
            "comparativo": r"(asÃ­\s+como|de\s+modo\s+semejante)"
        }

    def detectar_falacias(self, texto: str):
        hallazgos = []
        for tipo, patron in self.patrones_falacias.items():
            for m in re.finditer(patron, texto, re.IGNORECASE):
                contexto = texto[max(0, m.start() - 60):m.end() + 60]
                hallazgos.append({"tipo": tipo, "fragmento": contexto.strip()})
        return hallazgos

    def clasificar_razonamiento(self, texto: str) -> str:
        conteos = {k: len(re.findall(v, texto, re.IGNORECASE))
                   for k, v in self.patrones_razonamiento.items()}
        return max(conteos, key=conteos.get) if any(conteos.values()) else "indeterminado"

    def clasificar_tipo_argumento(self, texto: str) -> str:
        conteos = {k: len(re.findall(v, texto, re.IGNORECASE))
                   for k, v in self.tipo_argumento_juridico.items()}
        return max(conteos, key=conteos.get) if any(conteos.values()) else "indeterminado"

    def analizar_documento_completo(self, texto: str) -> Dict:
        """MÃ©todo auxiliar para compatibilidad con clase base."""
        palabras = len(texto.split())
        oraciones = len(re.split(r'[.!?]+', texto))
        promedio = palabras / max(1, oraciones)
        
        return {
            "nivel_dialectico": min(1.0, promedio / 25.0),
            "palabras": palabras,
            "oraciones": oraciones
        }

    def evaluar_argumentacion_juridica(self, texto: str) -> Dict:
        base = self.analizar_documento_completo(texto)
        falacias = self.detectar_falacias(texto)
        tipo_r = self.clasificar_razonamiento(texto)
        tipo_a = self.clasificar_tipo_argumento(texto)
        penal = min(0.35, len(falacias) * 0.04)
        irj = max(0.0, min(1.0, base.get("nivel_dialectico", 0.5) + 0.5 - penal))
        return {
            "tipo_razonamiento": tipo_r,
            "tipo_argumento": tipo_a,
            "falacias": falacias,
            "indice_razonamiento_juridico": round(irj, 3),
            "nivel_dialectico": base.get("nivel_dialectico", 0.5)
        }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ANALIZADOR ESTRUCTURAL DE SENTENCIAS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class AnalizadorEstructuralSentencias:
    """Analiza estructura judicial: VISTO, CONSIDERANDO, RESUELVO."""
    
    def __init__(self):
        self.secciones = ["VISTO", "CONSIDERANDO", "RESUELVO"]
    
    def analizar_sentencia_completa(self, texto: str) -> Dict:
        """Detecta secciones estructurales de la sentencia."""
        resultado = {}
        for seccion in self.secciones:
            patron = rf'\b{seccion}\b'
            if re.search(patron, texto, re.IGNORECASE):
                resultado[seccion.lower()] = True
            else:
                resultado[seccion.lower()] = False
        
        resultado["estructura_completa"] = all(resultado.values())
        return resultado


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ANALIZADOR INTEGRAL RAG
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class AnalizadorIntegralRAG(AnalizadorEnriquecidoRAG):
    """Integra anÃ¡lisis enriquecido, argumentativo y estructural."""

    def __init__(self, directorio_bases: Optional[str] = None):
        super().__init__()
        self.argumentativo = AnalizadorArgumentativoJuridico()
        self.estructural = AnalizadorEstructuralSentencias()
        self.directorio_bases = directorio_bases or "colaborative/vector_bases"

    def analizar_completo_texto(self, texto: str, tipo: str = "doctrina") -> Dict:
        if not texto or len(texto.strip()) < 30:
            return {"error": "Texto insuficiente", "tipo": tipo}

        enr = super().analizar_documento_completo(texto)
        arg = self.argumentativo.evaluar_argumentacion_juridica(texto)
        est = self.estructural.analizar_sentencia_completa(texto) if tipo == "sentencia" else {}
        irj, dial = arg.get("indice_razonamiento_juridico", 0), arg.get("nivel_dialectico", 0)
        return {
            "tipo": tipo,
            "analisis_enriquecido": enr,
            "analisis_argumentativo": arg,
            "analisis_estructural": est,
            "indice_integridad_argumental": round((irj + dial) / 2, 3),
            "numero_falacias": len(arg.get("falacias", []))
        }

    def analizar_documento_ruta(self, ruta_doc: str, tipo: str = "sentencia") -> Dict:
        texto = _recuperar_texto_desde_base_stub(ruta_doc) or _leer_texto_fallback(ruta_doc)
        if not texto:
            return {"error": f"No se pudo leer {ruta_doc}"}
        resultado = self.analizar_completo_texto(texto, tipo)
        resultado["archivo"] = os.path.basename(ruta_doc)
        return resultado


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GESTOR DE METADATOS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class GestorMetadatosSentencias:
    def __init__(self, ruta_json: str = "colaborative/data/pdfs/general/metadatos_sentencias.json"):
        self.ruta_json = ruta_json
        self.datos = {}
        if os.path.exists(ruta_json):
            with open(ruta_json, "r", encoding="utf-8") as f:
                self.datos = json.load(f)

    def obtener_para_archivo(self, nombre_archivo: str) -> dict:
        """Obtiene metadatos para un archivo especÃ­fico."""
        base = os.path.basename(nombre_archivo)
        # Buscar directamente por nombre de archivo (estructura plana)
        if base in self.datos and not base.startswith('_'):
            return self.datos[base]
        return {}


class AnalizadorIntegralRAGConMetadatos(AnalizadorIntegralRAG):
    """Analizador integral con enriquecimiento por metadatos JSON."""

    def __init__(self, ruta_metadatos: str = "colaborative/data/pdfs/general/metadatos_sentencias.json"):
        super().__init__()
        self.metadatos = GestorMetadatosSentencias(ruta_metadatos)

    def analizar_documento_ruta(self, ruta_doc: str, tipo: str = "sentencia") -> dict:
        resultado = super().analizar_documento_ruta(ruta_doc, tipo)
        meta = self.metadatos.obtener_para_archivo(ruta_doc)
        if meta:
            resultado["metadatos"] = meta
            if "ponderacion_manual" in meta:
                resultado["ponderacion_manual"] = meta["ponderacion_manual"]
        return resultado


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TEST DE INTEGRACIÃ“N
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def test_analizador_integral():
    """Test del analizador integral con metadatos."""
    print("\n" + "="*70)
    print("ğŸ§ª TEST ANALIZADOR INTEGRAL RAG CON METADATOS")
    print("="*70 + "\n")
    
    ruta_demo = "colaborative/data/pdfs/pdfs_civil_general/Banco_Provincia_c_Laborda_Walter_Gaston.pdf"
    
    if not os.path.exists(ruta_demo):
        print(f"âš ï¸ Archivo de prueba no encontrado: {ruta_demo}")
        print("ğŸ“ Para probar, coloca el PDF en la ruta indicada")
        return
    
    analizador = AnalizadorIntegralRAGConMetadatos()
    print(f"ğŸ“„ Analizando: {os.path.basename(ruta_demo)}\n")
    
    res = analizador.analizar_documento_ruta(ruta_demo, tipo="sentencia")
    
    print("ğŸ“Š RESULTADOS:")
    print(json.dumps(res, indent=2, ensure_ascii=False))
    
    if "metadatos" in res:
        print("\nâœ… Metadatos cargados correctamente desde JSON")
    else:
        print("\nâš ï¸ No se encontraron metadatos para este archivo")


if __name__ == "__main__":
    # Ejecutar test original
    probar_analizador()
    
    # Ejecutar test de integraciÃ³n si se descomenta:
    # test_analizador_integral()

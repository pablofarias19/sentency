#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üß† MOTOR MEJORADO ANALYSER M√âTODO v2.0
=====================================

IMPLEMENTA MEJORAS INTEGRALES:
- Esquema JSON unificado (perfil_autoral.json)
- Taxonom√≠a ampliada (14 tipos de razonamiento)
- Patrones regex avanzados
- Detecci√≥n de estructuras argumentativas
- An√°lisis de dogmas, valores y sesgos
- Compatible con sistema existente

AUTOR: Sistema Cognitivo v5.0 - Mejoras Integrales
FECHA: 9 NOV 2025
"""

import os
import re
import json
import sqlite3
from datetime import datetime
from typing import Dict, List, Any, Tuple
from dataclasses import dataclass
import math
from validador_contexto_retorica import ValidadorContextoRetorica

# PATRONES EXPANDIDOS PARA AN√ÅLISIS PROFUNDO
RAZONAMIENTO_PATTERNS = {
    "deductivo": r"\b(por tanto|en consecuencia|se concluye|se sigue|de( ah√≠| all√≠) que)\b",
    "inductivo": r"\b(en general|por lo com√∫n|habitualmente|frecuentemente|muestras|patrones)\b",
    "abductivo": r"\b(la mejor explicaci√≥n|explicar√≠a|hip√≥tesis plausible|inferencia a la mejor explicaci√≥n)\b",
    "analogico": r"\b(similar|semejante|como|an√°logamente|por analog√≠a)\b",
    "teleologico": r"\b(finalidad|prop√≥sito|objetivo|fin|meta)\b",
    "sistemico": r"\b(coherente|articulado|integrado|sistem√°tico|hol√≠stico|subsistemas)\b",
    "autoritativo": r"\b(doctrina (establece|dice)|jurisprudencia|precedente|fallos:?)\b",
    "a_contrario": r"\b(a contrario|por el contrario|inversamente|contrario sensu)\b",
    "consecuencialista": r"\b(consecuencias|efectos|resultados|impacto|externalidades)\b",
    "dialectico": r"\b(tesis|ant√≠tesis|s√≠ntesis|contraargumento|r√©plica|objecci√≥n)\b",
    "hermeneutico": r"\b(interpretaci√≥n|sentido|contexto|hermen[e√©]utica|telos|ratio)\b",
    "historico": r"\b(hist√≥ricamente|evoluci√≥n|contexto hist√≥rico|precedentes cronol√≥gicos)\b",
    "economico_analitico": r"\b(costos?|beneficios?|eficiencia|incentivos|trade-?off|√≥ptimo)\b",
    "reduccion_al_absurdo": r"\b(suponiendo que|si se admitiera que.*(absurdo|contradicci√≥n))\b"
}

MODALIDAD_EPISTEMICA_PATTERNS = {
    "apodictico": r"\b(indudable|inequ√≠voco|concluyente|necesario|demostrable)\b",
    "dialectico": r"\b(probable|veros√≠mil|opinable|controvertido|discutible)\b",
    "retorico": r"\b(persuasi√≥n|audiencia|verosimilitud|credibilidad|convincente)\b",
    "sofistico": r"\b(aparentemente|truco argumental|equivocaci√≥n|falacia)\b",
    "certeza": r"\b(indudable|inequ√≠voco|concluyente|necesario|cierto)\b",
    "incertidumbre_explorada": r"\b(incertidumbre|ambig√ºedad|no concluyente|limitado)\b",
    "hedging": r"\b(probablemente|posiblemente|podr√≠a|parece|sugiere|eventual)\b"
}

RETORICA_PATTERNS = {
    "ethos": r"\b(seg√∫n|conforme|establece la doctrina|jurisprudencia|autoridades? en la materia)\b",
    "pathos": r"\b(injusto|grave|alarmante|indignante|necesario|urgente|desproporcionado)\b",
    "logos": r"\b(porque|dado que|puesto que|en virtud de|la raz√≥n|por razones)\b"
}

ESTILOS_LITERARIOS = {
    "tecnico_juridico": [r"\b(art\.?|arts\.?|ley\s?\d+|decreto|fallos:|fs\.)\b", r"\b(v.gr\.|cfr\.)\b"],
    "ensayistico": [r"\b(pienso|considero|propongo|ensayo)\b", r"[;:‚Äî]\s"],
    "narrativo": [r"\b(primero|luego|entonces|finalmente)\b", r"\b(relata|narra)\b"],
    "barroco": [r"(,){3,}", r"\((?:[^()]+|\([^()]*\))*\)"],  # oraciones muy anidadas
    "minimalista": [r"\.\s+[A-Z√Å√â√ç√ì√ö√ë]"],  # frases cortas repetidas
    "aforistico": [r"\"[^\"]{5,120}\"", r"\b(aforismo|m√°xima)\b"],
    "impersonal_burocratico": [r"\b(se|queda|h√°gase|c√≠tese|notif√≠quese)\b", r"\b(que se provea|t√≥mese raz√≥n)\b"],
    "dialectico_critico": [r"\b(cr√≠tica|antinomia|paradoja|apor√≠a)\b"]
}

FALACIAS_HINTS = {
    "ad_hominem": r"\b(ignorante|incompetente|malicioso)\b",
    "ad_populum": r"\b(todo el mundo|es sabido que|la mayor√≠a)\b",
    "petitio_principii": r"\b(como es evidente que|resulta obvio que)\b",
    "falsa_analogia": r"\b(como.*tambi√©n.*entonces)\b",
    "falso_dilema": r"\b(o bien.*|no hay alternativa)\b",
    "slippery_slope": r"\b(inevitablemente|irremediablemente)\b"
}

AXIOMAS = {
    "principio_protectorio": r"\b(protectorio|pro operario|in dubio pro operario)\b",
    "autonomia_voluntad_limitada": r"\b(l√≠mites|orden p√∫blico|buenas costumbres|abuso del derecho)\b",
    "razonabilidad": r"\b(razonable|proporcionalidad|idoneidad|necesidad)\b",
    "seguridad_juridica": r"\b(seguridad jur[i√≠]dica|previsibilidad|confianza)\b"
}

SESGOS_VALORATIVOS = {
    "pro_trabajador": r"\b(trabajador|asalariado|protecci√≥n laboral)\b",
    "pro_empresario": r"\b(competitividad|inversi√≥n|productividad|eficiencia)\b",
    "pro_consumidor": r"\b(consumidor|hipervulnerable|relaci√≥n de consumo)\b",
    "garantista": r"\b(garant√≠as|debido proceso|tutela judicial efectiva)\b",
    "punitivista": r"\b(sanci√≥n ejemplar|multas severas|tolerancia cero)\b",
    "liberal": r"\b(libertad contractual|minima intervenci√≥n estatal)\b",
    "utilitarista": r"\b(bienestar general|eficiencia social|maximizaci√≥n del beneficio)\b"
}

FUENTES = {
    "jurisprudencia": r"\b(Fallos:|CSJN|SCBA|TSJ|C√°mara|Sala|Expte\.?)\b",
    "doctrina": r"\b(opina|sostiene|doctrina|tratadista|autor)\b",
    "ley": r"\b(ley\s?\d+|art(?:s?)\.?\s?\d+)\b",
    "principios": r"\b(principio|proporcionalidad|razonabilidad|equidad)\b",
    "politicas_publicas": r"\b(pol√≠tica p√∫blica|impacto regulatorio|an√°lisis econ√≥mico)\b",
    "evidencia_empirica": r"\b(estad√≠stic|datos|encuesta|muestra|regresi√≥n|dataset)\b"
}

class AnalyserMetodoMejorado:
    """Motor ANALYSER M√âTODO mejorado con taxonom√≠a expandida"""
    
    def __init__(self):
        self.version = "v2.0_mejorado"
        
    def score_pattern(self, text: str, pattern: str) -> float:
        """Scoring r√°pido por conteos normalizados"""
        matches = re.findall(pattern, text, flags=re.IGNORECASE | re.MULTILINE)
        return min(1.0, len(matches) / max(1, len(text) // 800))
    
    def score_group(self, text: str, patterns_dict: Dict[str, str]) -> Dict[str, float]:
        """Score m√∫ltiples patrones"""
        return {k: self.score_pattern(text, p) for k, p in patterns_dict.items()}
    
    def score_style_group(self, text: str, patterns_list: List[str]) -> float:
        """Score grupo de estilos (lista de subpatrones)"""
        total_score = 0.0
        for pattern in patterns_list:
            total_score += self.score_pattern(text, pattern)
        return min(1.0, total_score / max(1, len(patterns_list)))
    
    def detectar_estructuras_argumentativas(self, text: str) -> Dict[str, float]:
        """Detecci√≥n de estructuras argumentativas heur√≠stica"""
        estructuras = {}
        
        # IRAC (Issue, Rule, Application, Conclusion)
        estructuras["IRAC"] = 1.0 if re.search(
            r"(issue|cuesti√≥n).*(regla|norma).*(aplicaci√≥n|an√°lisis).*(conclusi√≥n)", 
            text, re.I | re.S
        ) else 0.0
        
        # Toulmin (Claim, Warrant, Backing)
        estructuras["Toulmin"] = 1.0 if re.search(
            r"(reclamo|pretensi√≥n).*(fundamento|garant√≠a).*(respaldo|backing)", 
            text, re.I | re.S
        ) else 0.0
        
        # Issue Tree
        estructuras["Issue_Tree"] = 1.0 if re.search(
            r"(subproblema|subcuesti√≥n|desglose)", text, re.I
        ) else 0.0
        
        # Defeasible reasoning
        estructuras["Defeasible"] = 1.0 if re.search(
            r"(salvo|a menos que|excepto si)", text, re.I
        ) else 0.0
        
        # Burden Shift
        estructuras["Burden_Shift"] = 1.0 if re.search(
            r"(carga de la prueba|onus probandi|corresponde demostrar)", text, re.I
        ) else 0.0
        
        # Silog√≠stico Formal
        estructuras["Silogistico_Formal"] = 1.0 if re.search(
            r"\b(Todo .* es .*)\b.*\b(Todo .* es .*)\b.*\b(Por tanto|Luego)\b.*", 
            text, re.I | re.S
        ) else 0.0
        
        return estructuras
    
    def detectar_falacias(self, text: str) -> List[str]:
        """Detecta falacias probables"""
        falacias_detectadas = []
        
        for falacia, pattern in FALACIAS_HINTS.items():
            if self.score_pattern(text, pattern) > 0.1:
                falacias_detectadas.append(falacia)
        
        return falacias_detectadas
    
    def extraer_dogmas_y_valores(self, text: str) -> Dict[str, Any]:
        """Extrae axiomas del autor, creencias y sesgos valorativos"""
        
        # Axiomas detectados
        axiomas_detectados = []
        for axioma, pattern in AXIOMAS.items():
            if self.score_pattern(text, pattern) > 0.1:
                axiomas_detectados.append(axioma)
        
        # Creencias expl√≠citas (heur√≠stica)
        creencias = []
        matches_creencias = re.findall(
            r"\b(creo que|considero que|estoy convencido que|es evidente que) ([^.]{10,100})\.", 
            text, re.I
        )
        creencias = [match[1].strip() for match in matches_creencias[:3]]
        
        # Sesgos valorativos
        sesgos = self.score_group(text, SESGOS_VALORATIVOS)
        
        return {
            "axiomas_autor": axiomas_detectados,
            "creencias_explicitas": creencias,
            "sesgos_valorativos": sesgos
        }
    
    def extraer_puntos_apoyo(self, text: str) -> Dict[str, Any]:
        """Extrae fuentes y puntos de apoyo del argumento"""
        
        intensidades = self.score_group(text, FUENTES)
        fuentes_principales = [k for k, v in intensidades.items() if v > 0.1]
        
        return {
            "fuentes": fuentes_principales,
            "intensidad_fuentes": intensidades
        }
    
    def extraer_dilemas_y_limites(self, text: str) -> Dict[str, Any]:
        """Extrae dilemas explicitados y limitaciones reconocidas"""
        
        # Dilemas (patr√≥n A vs B)
        dilemas = re.findall(r"\b(\w+)\s+vs\.?\s+(\w+)\b", text, re.I)
        dilemas_str = [f"{a}_vs_{b}" for a, b in dilemas]
        
        # Limitaciones reconocidas
        limitaciones_matches = re.findall(
            r"\b(limitaci√≥n|l√≠mite|sesgo|parcialidad|datos incompletos|no concluyente) ([^.]{5,80})\.", 
            text, re.I
        )
        limitaciones = [match[1].strip() for match in limitaciones_matches[:3]]
        
        # √Åreas de ambig√ºedad
        ambiguedad_matches = re.findall(
            r"\b(ambig√ºedad|imprecisi√≥n|zona gris|territorio inexplorado) ([^.]{5,80})\.", 
            text, re.I
        )
        ambiguedades = [match[1].strip() for match in ambiguedad_matches[:3]]
        
        return {
            "dilemas_explicitados": dilemas_str,
            "limitaciones_reconocidas": limitaciones,
            "areas_de_ambiguedad": ambiguedades
        }
    
    def calcular_marcadores_cognitivos(self, text: str) -> Dict[str, float]:
        """Calcula marcadores cognitivos expandidos"""
        
        return {
            "nivel_abstraccion": min(1.0, len(re.findall(r"\b(principio|cl√°usula general|ratio)\b", text, re.I)) / 5),
            "complejidad_sintactica": min(1.0, sum(1 for _ in re.finditer(r",", text)) / max(1, len(text) // 500)),
            "interdisciplinariedad": self.score_pattern(text, r"\b(econ√≥mico|sociol√≥gico|filos√≥fico|psicol√≥gico)\b"),
            "empirismo": self.score_pattern(text, r"\b(datos|muestra|estad√≠stic|evidencia)\b"),
            "dogmatismo": self.score_pattern(text, r"\b(indudable|inequ√≠voco|sin lugar a dudas)\b"),
            "creatividad": self.score_pattern(text, r"\b(propongo|novedoso|innovador|reinterpretaci√≥n)\b"),
            "uso_jurisprudencia": self.score_pattern(text, r"(Fallos:|C√°m\.|TSJ|SCBA|CSJN|Expte\.?)"),
            "coherencia_global": 0.5  # placeholder - se puede mejorar con an√°lisis de conectores
        }
    
    def generar_perfil_autoral_completo(self, texto: str, autor: str = None, fuente: str = None) -> Dict[str, Any]:
        """Genera perfil autoral completo seg√∫n esquema JSON unificado"""
        
        print(f"üß† Generando perfil autoral completo para: {autor or 'Autor desconocido'}")
        
        # An√°lisis de estilos literarios
        estilos_scores = {}
        for estilo, patterns in ESTILOS_LITERARIOS.items():
            estilos_scores[estilo] = self.score_style_group(texto, patterns)
        
        # Perfil completo seg√∫n esquema unificado
        perfil_autoral = {
            "meta": {
                "autor_probable": autor,
                "fuente": fuente or "texto_directo",
                "timestamp": datetime.now().isoformat(),
                "version_analyser": self.version
            },
            "cognicion": {
                "razonamiento_formal": self.score_group(texto, RAZONAMIENTO_PATTERNS),
                "modalidad_epistemica": self.score_group(texto, MODALIDAD_EPISTEMICA_PATTERNS),
                "retorica": {
                    **self.score_group(texto, RETORICA_PATTERNS),
                    "falacias_probables": self.detectar_falacias(texto)
                },
                "estilo_literario": estilos_scores,
                "estructuras_argumentativas": self.detectar_estructuras_argumentativas(texto)
            },
            "dogmas_y_valores": self.extraer_dogmas_y_valores(texto),
            "puntos_de_apoyo": self.extraer_puntos_apoyo(texto),
            "dilemas_y_limites": self.extraer_dilemas_y_limites(texto),
            "marcadores_cognitivos": self.calcular_marcadores_cognitivos(texto)
        }
        
        return perfil_autoral
    
    def generar_prompt_mejorado(self, chunk: str) -> str:
        """Genera prompt enriquecido para LLM externo"""
        
        return f"""
Eres METOD√ìLOGO JUR√çDICO y ANALISTA COGNITIVO. Describe C√ìMO PIENSA el autor (no qu√© dice).
Devuelve SOLO JSON con el esquema 'perfil_autoral.json'.

Eval√∫a:
1) Razonamiento formal (deductivo, inductivo, abductivo, anal√≥gico, teleol√≥gico, sist√©mico, autoritativo, a contrario, consecuencialista, dial√©ctico, hermen√©utico, hist√≥rico, econ√≥mico-anal√≠tico, reducci√≥n al absurdo).
2) Modalidad epist√©mica (apod√≠ctico, dial√©ctico, ret√≥rico, sof√≠stico, certeza, incertidumbre explorada, hedging).
3) Ret√≥rica (ethos, pathos, logos, falacias probables).
4) Estilo literario (t√©cnico-jur√≠dico, ensay√≠stico, narrativo, barroco, minimalista, afor√≠stico, impersonal-burocr√°tico, dial√©ctico-cr√≠tico).
5) Estructuras argumentativas (IRAC, Toulmin, Issue Tree, Defeasible, Burden Shift, Silog√≠stico Formal).
6) Dogmas y valores (axiomas, creencias, sesgos valorativos).
7) Puntos de apoyo (jurisprudencia, doctrina, ley, principios, pol√≠ticas p√∫blicas, evidencia emp√≠rica).
8) Dilemas y l√≠mites (dilemas explicitados, limitaciones reconocidas, √°reas de ambig√ºedad).
9) Marcadores cognitivos (nivel de abstracci√≥n, complejidad sint√°ctica, interdisciplinariedad, empirismo, dogmatismo, creatividad, uso de jurisprudencia, coherencia global).

Texto:
{chunk}
"""
    
    def guardar_perfil_en_db(self, perfil: Dict[str, Any], db_path: str = "colaborative/bases_rag/cognitiva/perfiles_autorales.db"):
        """Guarda perfil en base de datos"""
        
        os.makedirs(os.path.dirname(db_path), exist_ok=True)
        
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # Crear tabla si no existe
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS perfiles_autorales_v2 (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                autor TEXT,
                fuente TEXT,
                perfil_json TEXT,
                razonamiento_dominante TEXT,
                estilo_dominante TEXT,
                modalidad_dominante TEXT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                version TEXT
            )
        ''')
        
        # Extraer elementos principales para indexaci√≥n
        razonamiento_scores = perfil['cognicion']['razonamiento_formal']
        razonamiento_dominante = max(razonamiento_scores.items(), key=lambda x: x[1])[0]
        
        estilo_scores = perfil['cognicion']['estilo_literario']
        estilo_dominante = max(estilo_scores.items(), key=lambda x: x[1])[0]
        
        modalidad_scores = perfil['cognicion']['modalidad_epistemica']
        modalidad_dominante = max(modalidad_scores.items(), key=lambda x: x[1])[0]
        
        # Insertar perfil
        cursor.execute('''
            INSERT INTO perfiles_autorales_v2 
            (autor, fuente, perfil_json, razonamiento_dominante, estilo_dominante, modalidad_dominante, version)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        ''', (
            perfil['meta']['autor_probable'],
            perfil['meta']['fuente'],
            json.dumps(perfil, ensure_ascii=False),
            razonamiento_dominante,
            estilo_dominante,
            modalidad_dominante,
            perfil['meta']['version_analyser']
        ))
        
        conn.commit()
        conn.close()
        
        print(f"üíæ Perfil guardado: {perfil['meta']['autor_probable']} - {razonamiento_dominante}")


    def procesar_texto_completo(self, texto: str, metadatos: Dict = None) -> Dict:
        """
        ‚≠ê M√âTODO PRINCIPAL - Procesa texto completo y genera perfil autoral
        
        Args:
            texto: Texto a analizar
            metadatos: Informaci√≥n adicional del documento
            
        Returns:
            Dict: Perfil autoral completo con 40+ dimensiones
        """
        return self.generar_perfil_autoral_completo(texto, metadatos)

def main():
    """Funci√≥n principal para probar el motor mejorado"""
    
    print("üöÄ INICIANDO ANALYSER M√âTODO MEJORADO v2.0")
    
    analyser = AnalyserMetodoMejorado()
    
    # Texto de ejemplo para prueba
    texto_ejemplo = """
    En primer lugar, debemos analizar sistem√°ticamente los elementos que configuran 
    esta figura jur√≠dica. La doctrina establece claramente que no puede haber 
    ambig√ºedad en la interpretaci√≥n. Por tanto, se sigue necesariamente que 
    la √∫nica opci√≥n viable es aplicar el criterio restrictivo.
    
    Como sostiene la jurisprudencia de la Corte Suprema, el principio protectorio
    debe ser interpretado en funci√≥n de la finalidad social que persigue. Sin embargo,
    reconozco que los datos disponibles son limitados y que existe una zona gris
    en la aplicaci√≥n pr√°ctica de esta norma.
    """
    
    # Generar perfil completo
    perfil = analyser.generar_perfil_autoral_completo(texto_ejemplo, "Autor de Prueba")
    
    print("\nüß† PERFIL AUTORAL GENERADO:")
    print(json.dumps(perfil, indent=2, ensure_ascii=False))
    
    # Guardar en base de datos
    analyser.guardar_perfil_en_db(perfil)
    
    print("\n‚úÖ Prueba completada exitosamente")

def detectar_ethos_pathos_logos(texto: str) -> dict:
    """Detecci√≥n contextual ponderada de ETHOS, PATHOS, LOGOS"""
    v = ValidadorContextoRetorica()
    ethos = v.analizar_ethos(texto)
    pathos = v.analizar_pathos(texto)
    logos = v.analizar_logos(texto)

    return {
        "ethos": len(ethos),
        "pathos": len(pathos),
        "logos": len(logos),
        "ponderacion_ethos": sum(e.confianza for e in ethos) / (len(ethos) or 1),
        "ponderacion_pathos": sum(p.confianza for p in pathos) / (len(pathos) or 1),
        "ponderacion_logos": sum(l.confianza for l in logos) / (len(logos) or 1),
    }

if __name__ == "__main__":
    main()
# -*- coding: utf-8 -*-
"""
===========================================================
 M√ìDULO DE VECTORIZACI√ìN COGNITIVA ‚Äì SISTEMA ANALYSER M√âTODO
===========================================================

Funci√≥n:
    Extrae rasgos de razonamiento jur√≠dico y genera vectores
    cognitivos para identificar patrones de pensamiento, estilo
    argumentativo y orientaci√≥n doctrinaria.

Dependencias:
    pip install sentence-transformers faiss-cpu numpy sqlite3
===========================================================
"""

import os
import json
import sqlite3
import numpy as np
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, Tuple, List, Optional

# Imports con manejo de errores
try:
    from sentence_transformers import SentenceTransformer
except ImportError:
    print("‚ùå Error: Instala sentence-transformers con: pip install sentence-transformers")
    raise

# ----------------------------------------------------------
# CONFIGURACI√ìN DE RUTAS
# ----------------------------------------------------------
BASE_PATH = Path(__file__).parent.parent
DB_PATH = BASE_PATH / "bases_rag" / "cognitiva" / "metadatos.db"
FAISS_PATH = BASE_PATH / "bases_rag" / "cognitiva" / "faiss_index"
CHROMA_PATH = BASE_PATH / "bases_rag" / "cognitiva" / "chroma_index"

# Crear rutas si no existen
FAISS_PATH.mkdir(parents=True, exist_ok=True)
CHROMA_PATH.mkdir(parents=True, exist_ok=True)
DB_PATH.parent.mkdir(parents=True, exist_ok=True)

print(f"üîß Configuraci√≥n de rutas:")
print(f"  üìÅ Base: {BASE_PATH}")
print(f"  üóÉÔ∏è DB: {DB_PATH}")
print(f"  üìä FAISS: {FAISS_PATH}")

# ----------------------------------------------------------
# INICIALIZACI√ìN DE BASE DE DATOS
# ----------------------------------------------------------
def init_cognitive_db():
    """Inicializa la base de datos de perfiles cognitivos"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    cursor.execute("""
    CREATE TABLE IF NOT EXISTS perfiles_cognitivos (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        autor TEXT NOT NULL,
        fuente TEXT NOT NULL,
        tipo_pensamiento TEXT DEFAULT 'indeterminado',
        formalismo REAL DEFAULT 0.0,
        creatividad REAL DEFAULT 0.0,
        dogmatismo REAL DEFAULT 0.0,
        empirismo REAL DEFAULT 0.0,
        interdisciplinariedad REAL DEFAULT 0.0,
        nivel_abstraccion REAL DEFAULT 0.5,
        complejidad_sintactica REAL DEFAULT 0.0,
        uso_jurisprudencia REAL DEFAULT 0.0,
        tono TEXT DEFAULT 'neutro',
        fecha_analisis DATETIME DEFAULT CURRENT_TIMESTAMP,
        vector_path TEXT NOT NULL,
        texto_muestra TEXT,
        UNIQUE(autor, fuente)
    )
    """)
    
    # √çndices para b√∫squedas eficientes
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_autor ON perfiles_cognitivos(autor)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_tipo ON perfiles_cognitivos(tipo_pensamiento)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_fecha ON perfiles_cognitivos(fecha_analisis)")
    
    conn.commit()
    conn.close()
    print("‚úÖ Base de datos cognitiva inicializada")

# Inicializar al importar
init_cognitive_db()

# ----------------------------------------------------------
# MODELO DE EMBEDDINGS
# ----------------------------------------------------------
print("üîπ Cargando modelo cognitivo (all-mpnet-base-v2)...")
try:
    model = SentenceTransformer('all-mpnet-base-v2')
    print("‚úÖ Modelo cargado exitosamente")
except Exception as e:
    print(f"‚ùå Error cargando modelo: {e}")
    raise

# ----------------------------------------------------------
# AN√ÅLISIS COGNITIVO AVANZADO
# ----------------------------------------------------------
def extraer_rasgos_cognitivos(texto: str) -> Dict[str, float]:
    """
    Extrae rasgos cognitivos espec√≠ficos del texto jur√≠dico.
    M√©tricas m√°s sofisticadas que la versi√≥n anterior.
    """
    if not texto or len(texto.strip()) < 50:
        return {
            "formalismo": 0.0,
            "creatividad": 0.0,
            "dogmatismo": 0.0,
            "empirismo": 0.0,
            "interdisciplinariedad": 0.0,
            "nivel_abstraccion": 0.5,
            "complejidad_sintactica": 0.0,
            "uso_jurisprudencia": 0.0
        }
    
    texto_lower = texto.lower()
    palabras = texto_lower.split()
    total_palabras = len(palabras) or 1
    oraciones = re.split(r'[.!?]+', texto)
    total_oraciones = len([s for s in oraciones if s.strip()]) or 1
    
    # 1. FORMALISMO JUR√çDICO
    indicadores_formales = [
        r'\bart\.\s*\d+', r'\binc\.\s*\d+', r'\bley\s+\d+',
        r'\bc√≥digo\s+civil', r'\bc√≥digo\s+penal', r'\bconstituci[√≥o]n',
        r'\bdecreto\s+\d+', r'\bresoluci[√≥o]n\s+\d+'
    ]
    formalismo = sum(len(re.findall(patron, texto_lower)) for patron in indicadores_formales) / total_palabras
    
    # 2. CREATIVIDAD INTERPRETATIVA
    indicadores_creativos = [
        'interpretaci[√≥o]n', 'reinterpret', 'nueva perspectiva', 'enfoque innovador',
        'propone', 'sugiere', 'plantea', 'considera', 'podr√≠amos entender',
        'cabe preguntarse', 'ser√≠a posible', 'alternativa'
    ]
    creatividad = sum(texto_lower.count(ind) for ind in indicadores_creativos) / total_palabras
    
    # 3. DOGMATISMO DOCTRINAL
    indicadores_dogmaticos = [
        'seg√∫n la doctrina', 'la doctrina ense√±a', 'es incuestionable', 'sin duda',
        'claramente establece', 'definitivamente', 'incondicionalmente',
        'tradicionalmente', 'cl√°sicamente', 'ortodoxamente'
    ]
    dogmatismo = sum(texto_lower.count(ind) for ind in indicadores_dogmaticos) / total_palabras
    
    # 4. EMPIRISMO (uso de casos, ejemplos)
    indicadores_empiricos = [
        r'\bcaso\b', r'\bejemplo\b', r'\bpr√°ctica\b', r'\bexperiencia\b',
        r'\bfallo\b', r'\bsentencia\b', r'\bjurisprudencia\b',
        r'\btribunal\b', r'\bcorte\b', r'\bjuzgado\b'
    ]
    empirismo = sum(len(re.findall(patron, texto_lower)) for patron in indicadores_empiricos) / total_palabras
    
    # 5. INTERDISCIPLINARIEDAD
    disciplinas = [
        'sociolog[√≠i]a', 'econom[√≠i]a', 'filosofia', 'psicolog[√≠i]a',
        'antropolog[√≠i]a', 'ciencia pol[√≠i]tica', 'historia',
        'ling√º[√≠i]stica', 'l[√≥o]gica', 'estad√≠stica'
    ]
    interdisciplinariedad = sum(len(re.findall(disc, texto_lower)) for disc in disciplinas) / total_palabras
    
    # 6. NIVEL DE ABSTRACCI√ìN
    indicadores_abstractos = [
        'principio', 'concepto', 'teor√≠a', 'fundamento', 'esencia',
        'naturaleza', 'categor√≠a', 'noci√≥n', 'idea', 'pensamiento'
    ]
    indicadores_concretos = [
        'espec√≠ficamente', 'concretamente', 'en particular', 'por ejemplo',
        'caso concreto', 'situaci√≥n espec√≠fica', 'aplicaci√≥n pr√°ctica'
    ]
    abstraccion_score = sum(texto_lower.count(ind) for ind in indicadores_abstractos)
    concreto_score = sum(texto_lower.count(ind) for ind in indicadores_concretos)
    
    if abstraccion_score + concreto_score > 0:
        nivel_abstraccion = abstraccion_score / (abstraccion_score + concreto_score)
    else:
        nivel_abstraccion = 0.5
    
    # 7. COMPLEJIDAD SINT√ÅCTICA
    palabras_por_oracion = total_palabras / total_oraciones
    complejidad_sintactica = min(palabras_por_oracion / 20.0, 1.0)  # Normalizado a [0,1]
    
    # 8. USO DE JURISPRUDENCIA
    indicadores_jurisprudenciales = [
        r'c\.s\.j\.n\.', r'corte suprema', r'c√°mara nacional', r'tribunal superior',
        r'fallo\s+\w+', r'sentencia\s+del', r'decidi√≥ que', r'sostuvo que',
        r'in re\s+\w+', r'autos\s+\w+'
    ]
    uso_jurisprudencia = sum(len(re.findall(patron, texto_lower)) for patron in indicadores_jurisprudenciales) / total_palabras
    
    return {
        "formalismo": min(formalismo * 100, 1.0),  # Escalar apropiadamente
        "creatividad": min(creatividad * 50, 1.0),
        "dogmatismo": min(dogmatismo * 20, 1.0),
        "empirismo": min(empirismo * 30, 1.0),
        "interdisciplinariedad": min(interdisciplinariedad * 100, 1.0),
        "nivel_abstraccion": nivel_abstraccion,
        "complejidad_sintactica": complejidad_sintactica,
        "uso_jurisprudencia": min(uso_jurisprudencia * 50, 1.0)
    }

def detectar_tipo_pensamiento(rasgos: Dict[str, float]) -> str:
    """
    Clasifica el tipo de pensamiento jur√≠dico basado en los rasgos extra√≠dos.
    """
    if rasgos["formalismo"] > 0.3:
        return "Formalista"
    elif rasgos["empirismo"] > 0.2:
        return "Realista"
    elif rasgos["creatividad"] > 0.15:
        return "Interpretativo"
    elif rasgos["dogmatismo"] > 0.1:
        return "Tradicionalista"
    elif rasgos["interdisciplinariedad"] > 0.05:
        return "Interdisciplinario"
    elif rasgos["nivel_abstraccion"] > 0.7:
        return "Conceptualista"
    else:
        return "Pragm√°tico"

def detectar_tono(texto: str) -> str:
    """
    Detecta el tono argumentativo del texto.
    """
    texto_lower = texto.lower()
    
    # Indicadores de tono
    critico = ['critica', 'cuestiona', 'refuta', 'objeta', 'contradice', 'err√≥neo', 'incorrecto']
    asertivo = ['afirma', 'sostiene', 'establece', 'demuestra', 'evidencia', 'claramente']
    cauteloso = ['quiz√°s', 'posiblemente', 'podr√≠a', 'cabr√≠a', 'eventualmente', 'en principio']
    
    puntos_critico = sum(texto_lower.count(ind) for ind in critico)
    puntos_asertivo = sum(texto_lower.count(ind) for ind in asertivo)
    puntos_cauteloso = sum(texto_lower.count(ind) for ind in cauteloso)
    
    if puntos_critico > puntos_asertivo and puntos_critico > puntos_cauteloso:
        return "cr√≠tico"
    elif puntos_asertivo > puntos_cauteloso:
        return "asertivo"
    elif puntos_cauteloso > 2:
        return "cauteloso"
    else:
        return "neutro"

# ----------------------------------------------------------
# FUNCI√ìN PRINCIPAL DE VECTORIZACI√ìN
# ----------------------------------------------------------
def generar_vector_cognitivo(texto: str) -> Tuple[np.ndarray, Dict[str, float]]:
    """
    Genera un vector que representa el perfil cognitivo del texto.
    Combina embeddings sem√°nticos con m√©tricas cognitivas espec√≠ficas.
    """
    if not texto or len(texto.strip()) < 100:
        raise ValueError("El texto es demasiado corto para an√°lisis cognitivo (m√≠nimo 100 caracteres).")

    # Embedding sem√°ntico base
    try:
        emb = model.encode(texto, normalize_embeddings=True)
    except Exception as e:
        raise ValueError(f"Error generando embedding: {e}")

    # Rasgos cognitivos espec√≠ficos
    rasgos = extraer_rasgos_cognitivos(texto)

    # Vector combinado: embedding + rasgos cognitivos
    vector_cognitivo = np.concatenate([
        emb, 
        np.array(list(rasgos.values()), dtype=np.float32)
    ])
    
    return vector_cognitivo, rasgos

# ----------------------------------------------------------
# REGISTRO EN BASE DE DATOS
# ----------------------------------------------------------
def registrar_perfil(autor: str, texto: str, fuente: str, texto_muestra: Optional[str] = None, 
                    metadatos_extra: Optional[Dict] = None) -> str:
    """
    Registra un perfil cognitivo en la base de datos y guarda el vector
    en un archivo .npy dentro del √≠ndice FAISS.
    """
    if not autor or not texto or not fuente:
        raise ValueError("Autor, texto y fuente son obligatorios")
    
    try:
        vector, rasgos = generar_vector_cognitivo(texto)
        
        # An√°lisis adicional
        tipo_pensamiento = detectar_tipo_pensamiento(rasgos)
        tono = detectar_tono(texto)
        
        # Generar nombre √∫nico para el archivo
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        autor_clean = re.sub(r'[^\w\s-]', '', autor).replace(' ', '_').lower()
        nombre_archivo = f"{autor_clean}_{timestamp}.npy"
        vector_path = FAISS_PATH / nombre_archivo
        
        # Guardar vector
        np.save(vector_path, vector)
        
        # Registrar en base de datos
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # Usar texto_muestra si se proporciona, sino tomar una muestra del texto
        muestra = texto_muestra or texto[:500] + "..." if len(texto) > 500 else texto
        
        # Procesar metadatos extra si est√°n disponibles
        metadatos_json = ""
        autor_confianza = 0.0
        razonamiento_dominante = ""
        modalidad_epistemica = ""
        estructura_silogistica = ""
        ethos = pathos = logos = 0.0
        
        if metadatos_extra:
            try:
                import json
                metadatos_json = json.dumps(metadatos_extra, ensure_ascii=False)
                
                # Extraer datos aristot√©licos si est√°n disponibles
                if "aristotelico" in metadatos_extra:
                    aristo = metadatos_extra["aristotelico"]
                    autor_principal = aristo.get("obra", {}).get("autor_principal", {})
                    autor_confianza = autor_principal.get("confianza", 0.0)
                    
                    analisis = aristo.get("analisis", {})
                    razonamiento = analisis.get("razonamiento", {})
                    if razonamiento.get("top3"):
                        razonamiento_dominante = razonamiento["top3"][0].get("clase", "")
                    
                    modalidad = analisis.get("modalidad_epistemica", {})
                    modalidad_epistemica = modalidad.get("predominante", {}).get("clase", "")
                    
                    silogismo = analisis.get("estructura_silogistica", {})
                    estructura_silogistica = silogismo.get("principal", {}).get("nombre", "")
                    
                    retorica = analisis.get("retorica", {})
                    ethos = retorica.get("ethos", 0.0)
                    pathos = retorica.get("pathos", 0.0)
                    logos = retorica.get("logos", 0.0)
            except Exception as e:
                print(f"‚ö†Ô∏è Error procesando metadatos extra: {e}")

        cursor.execute("""
            INSERT OR REPLACE INTO perfiles_cognitivos
            (autor, fuente, tipo_pensamiento, formalismo, creatividad, dogmatismo, 
             empirismo, interdisciplinariedad, nivel_abstraccion, complejidad_sintactica,
             uso_jurisprudencia, tono, vector_path, texto_muestra, fecha_analisis,
             metadatos_json, autor_confianza, razonamiento_dominante, modalidad_epistemica,
             estructura_silogistica, ethos, pathos, logos)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            autor, fuente, tipo_pensamiento,
            rasgos["formalismo"], rasgos["creatividad"], rasgos["dogmatismo"],
            rasgos["empirismo"], rasgos["interdisciplinariedad"], rasgos["nivel_abstraccion"],
            rasgos["complejidad_sintactica"], rasgos["uso_jurisprudencia"],
            tono, str(vector_path), muestra, datetime.now().isoformat(),
            metadatos_json, autor_confianza, razonamiento_dominante, modalidad_epistemica,
            estructura_silogistica, ethos, pathos, logos
        ))
        
        conn.commit()
        conn.close()
        
        print(f"‚úÖ Perfil cognitivo registrado:")
        print(f"  üë§ Autor: {autor}")
        print(f"  üìÑ Fuente: {fuente}")
        print(f"  üß† Tipo: {tipo_pensamiento}")
        print(f"  üé≠ Tono: {tono}")
        print(f"  üìä Rasgos: {dict(list(rasgos.items())[:4])}")
        
        return str(vector_path)
        
    except Exception as e:
        print(f"‚ùå Error registrando perfil: {e}")
        raise

# ----------------------------------------------------------
# FUNCIONES DE CONSULTA
# ----------------------------------------------------------
def listar_perfiles(limit: int = 10) -> List[Tuple]:
    """Devuelve una lista de perfiles registrados en la base de datos."""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    cursor.execute("""
        SELECT id, autor, tipo_pensamiento, tono, fecha_analisis, fuente
        FROM perfiles_cognitivos 
        ORDER BY fecha_analisis DESC 
        LIMIT ?
    """, (limit,))
    
    resultados = cursor.fetchall()
    conn.close()
    return resultados

def obtener_estadisticas() -> Dict:
    """Retorna estad√≠sticas generales de los perfiles"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # Estad√≠sticas b√°sicas
    cursor.execute("SELECT COUNT(*) FROM perfiles_cognitivos")
    total = cursor.fetchone()[0]
    
    cursor.execute("SELECT tipo_pensamiento, COUNT(*) FROM perfiles_cognitivos GROUP BY tipo_pensamiento")
    tipos = dict(cursor.fetchall())
    
    cursor.execute("SELECT tono, COUNT(*) FROM perfiles_cognitivos GROUP BY tono")
    tonos = dict(cursor.fetchall())
    
    cursor.execute("SELECT AVG(formalismo), AVG(creatividad), AVG(empirismo) FROM perfiles_cognitivos")
    promedios = cursor.fetchone()
    
    conn.close()
    
    return {
        "total_perfiles": total,
        "tipos_pensamiento": tipos,
        "distribuci√≥n_tonos": tonos,
        "promedios": {
            "formalismo": promedios[0] or 0,
            "creatividad": promedios[1] or 0,
            "empirismo": promedios[2] or 0
        }
    }

# ----------------------------------------------------------
# MODO DE USO DIRECTO
# ----------------------------------------------------------
if __name__ == "__main__":
    print("\nüß† VECTORIZADOR COGNITIVO ACTIVO\n")
    
    # Ejemplo de uso
    ejemplo_texto = """
    La aplicaci√≥n del art√≠culo 1197 del C√≥digo Civil argentino establece claramente 
    que las convenciones hechas en los contratos forman para las partes una regla 
    a la cual deben someterse como a la ley misma. Sin embargo, la jurisprudencia 
    de la Corte Suprema ha sostenido que este principio debe interpretarse 
    conforme a los postulados de la buena fe contractual. En el caso "Banco de 
    Boston c/ Garc√≠a" la Corte decidi√≥ que la autonom√≠a de la voluntad encuentra 
    l√≠mites en el orden p√∫blico y las buenas costumbres.
    """
    
    autor_ejemplo = "Dr. Juan P√©rez"
    fuente_ejemplo = "Manual de Derecho Civil - Contratos"
    
    try:
        path = registrar_perfil(autor_ejemplo, ejemplo_texto, fuente_ejemplo)
        print(f"\nüîó Vector guardado en: {path}")
        
        print("\nüìä Estad√≠sticas generales:")
        stats = obtener_estadisticas()
        for clave, valor in stats.items():
            print(f"  {clave}: {valor}")
        
        print("\nüìã √öltimos perfiles registrados:")
        perfiles = listar_perfiles(5)
        for perfil in perfiles:
            print(f"  ‚Ä¢ {perfil[1]} ({perfil[2]}) - {perfil[4]}")
            
    except Exception as e:
        print(f"‚ùå Error en ejemplo: {e}")
        
    print("\n‚úÖ Vectorizador cognitivo listo para uso.")